{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 06: Advanced Azure Video Indexer\n",
    "\n",
    "## Overview\n",
    "This advanced notebook explores sophisticated video analysis capabilities using Azure Video Indexer. You'll learn about custom models, advanced audio analysis, video moderation, batch processing, and integration with other Azure services.\n",
    "\n",
    "## Advanced Topics Covered\n",
    "- Custom models for brands and people recognition\n",
    "- Video content moderation and compliance\n",
    "- Advanced audio analysis and speaker identification\n",
    "- Scene and shot detection\n",
    "- Keyframe extraction and thumbnail generation\n",
    "- Batch video processing workflows\n",
    "- Integration with Azure services (Storage, Logic Apps, Functions)\n",
    "- Video editing and clipping\n",
    "- Custom language models\n",
    "- Observed people tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests python-dotenv pandas matplotlib pillow azure-storage-blob -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML, Image, Markdown\n",
    "\n",
    "# Load configuration\n",
    "load_dotenv('python/.env')\n",
    "\n",
    "# Video Indexer configuration\n",
    "VIDEO_INDEXER_ACCOUNT_ID = os.getenv(\"VIDEO_INDEXER_ACCOUNT_ID\")\n",
    "VIDEO_INDEXER_API_KEY = os.getenv(\"VIDEO_INDEXER_API_KEY\")\n",
    "VIDEO_INDEXER_LOCATION = os.getenv(\"VIDEO_INDEXER_LOCATION\", \"trial\")\n",
    "\n",
    "API_BASE_URL = \"https://api.videoindexer.ai\"\n",
    "\n",
    "if VIDEO_INDEXER_ACCOUNT_ID and VIDEO_INDEXER_API_KEY:\n",
    "    print(\"✓ Video Indexer configuration loaded\")\n",
    "else:\n",
    "    print(\"⚠ Warning: Video Indexer credentials not found\")\n",
    "\n",
    "# Helper function to get access token\n",
    "def get_access_token() -> str:\n",
    "    \"\"\"Get Video Indexer access token.\"\"\"\n",
    "    url = f\"{API_BASE_URL}/auth/{VIDEO_INDEXER_LOCATION}/Accounts/{VIDEO_INDEXER_ACCOUNT_ID}/AccessToken\"\n",
    "    headers = {\"Ocp-Apim-Subscription-Key\": VIDEO_INDEXER_API_KEY}\n",
    "    params = {\"allowEdit\": \"true\"}\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json().strip('\"')\n",
    "\n",
    "if VIDEO_INDEXER_ACCOUNT_ID and VIDEO_INDEXER_API_KEY:\n",
    "    try:\n",
    "        access_token = get_access_token()\n",
    "        print(\"✓ Access token obtained\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        access_token = None\n",
    "else:\n",
    "    access_token = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Custom Brand Models\n",
    "\n",
    "Create custom models to detect specific brands, products, or terminology in videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brand_model(model_name: str, brands: List[Dict], \n",
    "                       access_token: str) -> Dict:\n",
    "    \"\"\"Create a custom brand model.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name for the brand model\n",
    "        brands: List of brand definitions with name, description, tags, etc.\n",
    "        access_token: Video Indexer access token\n",
    "    \n",
    "    Example brands format:\n",
    "    [\n",
    "        {\n",
    "            \"name\": \"MyBrand\",\n",
    "            \"description\": \"Company brand\",\n",
    "            \"tags\": [\"brand\", \"company\"],\n",
    "            \"enabled\": True\n",
    "        }\n",
    "    ]\n",
    "    \"\"\"\n",
    "    url = f\"{API_BASE_URL}/{VIDEO_INDEXER_LOCATION}/Accounts/{VIDEO_INDEXER_ACCOUNT_ID}/Customization/BrandModels\"\n",
    "    \n",
    "    params = {\n",
    "        \"accessToken\": access_token,\n",
    "        \"name\": model_name\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    model = response.json()\n",
    "    \n",
    "    print(f\"✓ Brand model created: {model_name}\")\n",
    "    print(f\"  Model ID: {model['id']}\")\n",
    "    \n",
    "    # Add brands to model\n",
    "    model_id = model['id']\n",
    "    for brand in brands:\n",
    "        add_brand_to_model(model_id, brand, access_token)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def add_brand_to_model(model_id: str, brand: Dict, access_token: str):\n",
    "    \"\"\"Add a brand to a custom model.\"\"\"\n",
    "    url = f\"{API_BASE_URL}/{VIDEO_INDEXER_LOCATION}/Accounts/{VIDEO_INDEXER_ACCOUNT_ID}/Customization/BrandModels/{model_id}/Brands\"\n",
    "    \n",
    "    params = {\n",
    "        \"accessToken\": access_token\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, params=params, json=brand)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    print(f\"  ✓ Added brand: {brand['name']}\")\n",
    "\n",
    "def list_brand_models(access_token: str) -> List[Dict]:\n",
    "    \"\"\"List all custom brand models.\"\"\"\n",
    "    url = f\"{API_BASE_URL}/{VIDEO_INDEXER_LOCATION}/Accounts/{VIDEO_INDEXER_ACCOUNT_ID}/Customization/BrandModels\"\n",
    "    \n",
    "    params = {\"accessToken\": access_token}\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "# Example usage\n",
    "print(\"\\n=== Custom Brand Models ===\")\n",
    "print(\"Custom brand models allow you to:\")\n",
    "print(\"  - Detect company-specific brands\")\n",
    "print(\"  - Track product mentions\")\n",
    "print(\"  - Monitor competitor brands\")\n",
    "print(\"  - Identify custom terminology\")\n",
    "print(\"\\nExample:\")\n",
    "print(\"  brands = [{'name': 'Contoso', 'enabled': True}]\")\n",
    "print(\"  model = create_brand_model('MyBrands', brands, access_token)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Custom People Models\n",
    "\n",
    "Train custom models to recognize specific individuals in videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_person_model(model_name: str, access_token: str) -> Dict:\n",
    "    \"\"\"Create a custom person model.\"\"\"\n",
    "    url = f\"{API_BASE_URL}/{VIDEO_INDEXER_LOCATION}/Accounts/{VIDEO_INDEXER_ACCOUNT_ID}/Customization/PersonModels\"\n",
    "    \n",
    "    params = {\n",
    "        \"accessToken\": access_token,\n",
    "        \"name\": model_name\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    model = response.json()\n",
    "    print(f\"✓ Person model created: {model_name}\")\n",
    "    print(f\"  Model ID: {model['id']}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def add_person_to_model(model_id: str, person_name: str, \n",
    "                        access_token: str) -> Dict:\n",
    "    \"\"\"Add a person to a custom model.\"\"\"\n",
    "    url = f\"{API_BASE_URL}/{VIDEO_INDEXER_LOCATION}/Accounts/{VIDEO_INDEXER_ACCOUNT_ID}/Customization/PersonModels/{model_id}/Persons\"\n",
    "    \n",
    "    params = {\n",
    "        \"accessToken\": access_token,\n",
    "        \"name\": person_name\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    person = response.json()\n",
    "    print(f\"  ✓ Added person: {person_name} (ID: {person['id']})\")\n",
    "    \n",
    "    return person\n",
    "\n",
    "def train_person_face(model_id: str, person_id: str, \n",
    "                     image_path: str, access_token: str):\n",
    "    \"\"\"Add a face image to train person recognition.\"\"\"\n",
    "    url = f\"{API_BASE_URL}/{VIDEO_INDEXER_LOCATION}/Accounts/{VIDEO_INDEXER_ACCOUNT_ID}/Customization/PersonModels/{model_id}/Persons/{person_id}/Faces\"\n",
    "    \n",
    "    params = {\"accessToken\": access_token}\n",
    "    \n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        files = {\"file\": img_file}\n",
    "        response = requests.post(url, params=params, files=files)\n",
    "        response.raise_for_status()\n",
    "    \n",
    "    print(f\"  ✓ Training image uploaded for person {person_id}\")\n",
    "\n",
    "def list_person_models(access_token: str) -> List[Dict]:\n",
    "    \"\"\"List all custom person models.\"\"\"\n",
    "    url = f\"{API_BASE_URL}/{VIDEO_INDEXER_LOCATION}/Accounts/{VIDEO_INDEXER_ACCOUNT_ID}/Customization/PersonModels\"\n",
    "    \n",
    "    params = {\"accessToken\": access_token}\n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "# Example usage\n",
    "print(\"\\n=== Custom People Models ===\")\n",
    "print(\"⚠ Note: Face recognition requires Limited Access approval from Microsoft\")\n",
    "print(\"\\nCustom people models enable:\")\n",
    "print(\"  - Recognition of specific individuals\")\n",
    "print(\"  - Employee or celebrity identification\")\n",
    "print(\"  - Speaker tracking across videos\")\n",
    "print(\"  - Personalized content indexing\")\n",
    "print(\"\\nWorkflow:\")\n",
    "print(\"  1. Create person model\")\n",
    "print(\"  2. Add persons to model\")\n",
    "print(\"  3. Upload training images for each person\")\n",
    "print(\"  4. Use model when indexing videos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Content Moderation and Compliance\n",
    "\n",
    "Detect and moderate inappropriate content in videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_content_moderation(insights: Dict) -> Dict:\n",
    "    \"\"\"Analyze content moderation results from video insights.\"\"\"\n",
    "    if 'videos' not in insights or len(insights['videos']) == 0:\n",
    "        return {}\n",
    "    \n",
    "    video_insights = insights['videos'][0]['insights']\n",
    "    \n",
    "    moderation_results = {\n",
    "        \"adult_content\": [],\n",
    "        \"racy_content\": [],\n",
    "        \"violent_content\": [],\n",
    "        \"inappropriate_text\": []\n",
    "    }\n",
    "    \n",
    "    # Check for adult/racy content in scenes\n",
    "    if 'scenes' in video_insights:\n",
    "        for scene in video_insights['scenes']:\n",
    "            if 'tags' in scene:\n",
    "                for tag in scene['tags']:\n",
    "                    # Check for content flags\n",
    "                    if 'adult' in tag.lower() or 'explicit' in tag.lower():\n",
    "                        moderation_results['adult_content'].append({\n",
    "                            'scene_id': scene['id'],\n",
    "                            'tag': tag\n",
    "                        })\n",
    "                    elif 'racy' in tag.lower() or 'suggestive' in tag.lower():\n",
    "                        moderation_results['racy_content'].append({\n",
    "                            'scene_id': scene['id'],\n",
    "                            'tag': tag\n",
    "                        })\n",
    "    \n",
    "    # Analyze transcript for inappropriate language\n",
    "    if 'transcript' in video_insights:\n",
    "        # Define inappropriate terms (simplified example)\n",
    "        inappropriate_terms = ['profanity', 'offensive']  # Add more as needed\n",
    "        \n",
    "        for segment in video_insights['transcript']:\n",
    "            text = segment.get('text', '').lower()\n",
    "            for term in inappropriate_terms:\n",
    "                if term in text:\n",
    "                    moderation_results['inappropriate_text'].append({\n",
    "                        'timestamp': segment.get('start'),\n",
    "                        'text': segment['text']\n",
    "                    })\n",
    "    \n",
    "    return moderation_results\n",
    "\n",
    "def generate_compliance_report(moderation_results: Dict) -> str:\n",
    "    \"\"\"Generate a compliance report based on moderation results.\"\"\"\n",
    "    report = []\n",
    "    report.append(\"# Content Moderation Report\")\n",
    "    report.append(\"\\n## Summary\")\n",
    "    \n",
    "    total_issues = sum(len(v) for v in moderation_results.values())\n",
    "    \n",
    "    if total_issues == 0:\n",
    "        report.append(\"✓ No content moderation issues detected.\")\n",
    "    else:\n",
    "        report.append(f\"⚠ {total_issues} potential issues detected.\")\n",
    "        \n",
    "        for category, issues in moderation_results.items():\n",
    "            if issues:\n",
    "                report.append(f\"\\n### {category.replace('_', ' ').title()}\")\n",
    "                report.append(f\"Found {len(issues)} instances:\")\n",
    "                for issue in issues[:5]:  # Show first 5\n",
    "                    report.append(f\"- {issue}\")\n",
    "    \n",
    "    report.append(\"\\n## Recommendations\")\n",
    "    report.append(\"- Review flagged content manually\")\n",
    "    report.append(\"- Consider age restrictions if necessary\")\n",
    "    report.append(\"- Add content warnings where appropriate\")\n",
    "    \n",
    "    return \"\\n\".join(report)\n",
    "\n",
    "# Example usage\n",
    "print(\"\\n=== Content Moderation ===\")\n",
    "print(\"Video Indexer provides content moderation for:\")\n",
    "print(\"  - Adult content detection\")\n",
    "print(\"  - Racy/suggestive content\")\n",
    "print(\"  - Violence detection\")\n",
    "print(\"  - Inappropriate language in transcript\")\n",
    "print(\"  - Compliance reporting\")\n",
    "print(\"\\nUse cases:\")\n",
    "print(\"  - Content filtering for platforms\")\n",
    "print(\"  - Age-appropriate content classification\")\n",
    "print(\"  - Brand safety monitoring\")\n",
    "print(\"  - Regulatory compliance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced Audio Analysis\n",
    "\n",
    "Perform detailed audio analysis including speaker separation and emotion detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_speakers(insights: Dict) -> Dict:\n",
    "    \"\"\"Analyze speaker information and diarization.\"\"\"\n",
    "    if 'videos' not in insights or len(insights['videos']) == 0:\n",
    "        return {}\n",
    "    \n",
    "    video_insights = insights['videos'][0]['insights']\n",
    "    \n",
    "    speaker_analysis = {\n",
    "        \"total_speakers\": 0,\n",
    "        \"speakers\": {},\n",
    "        \"speaker_timeline\": []\n",
    "    }\n",
    "    \n",
    "    # Analyze transcript for speaker information\n",
    "    if 'transcript' in video_insights:\n",
    "        speakers_found = set()\n",
    "        \n",
    "        for segment in video_insights['transcript']:\n",
    "            speaker_id = segment.get('speakerId')\n",
    "            \n",
    "            if speaker_id:\n",
    "                speakers_found.add(speaker_id)\n",
    "                \n",
    "                if speaker_id not in speaker_analysis['speakers']:\n",
    "                    speaker_analysis['speakers'][speaker_id] = {\n",
    "                        'segments': [],\n",
    "                        'total_duration': 0,\n",
    "                        'word_count': 0\n",
    "                    }\n",
    "                \n",
    "                speaker_info = speaker_analysis['speakers'][speaker_id]\n",
    "                speaker_info['segments'].append(segment['text'])\n",
    "                speaker_info['word_count'] += len(segment['text'].split())\n",
    "                \n",
    "                speaker_analysis['speaker_timeline'].append({\n",
    "                    'speaker_id': speaker_id,\n",
    "                    'start': segment.get('start'),\n",
    "                    'text': segment['text']\n",
    "                })\n",
    "        \n",
    "        speaker_analysis['total_speakers'] = len(speakers_found)\n",
    "    \n",
    "    return speaker_analysis\n",
    "\n",
    "def visualize_speaker_distribution(speaker_analysis: Dict):\n",
    "    \"\"\"Visualize speaker contribution in the video.\"\"\"\n",
    "    if not speaker_analysis.get('speakers'):\n",
    "        print(\"No speaker data available\")\n",
    "        return\n",
    "    \n",
    "    speakers = speaker_analysis['speakers']\n",
    "    speaker_ids = list(speakers.keys())\n",
    "    word_counts = [speakers[sid]['word_count'] for sid in speaker_ids]\n",
    "    \n",
    "    # Create bar chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.bar(speaker_ids, word_counts, color='steelblue')\n",
    "    ax.set_xlabel('Speaker ID')\n",
    "    ax.set_ylabel('Word Count')\n",
    "    ax.set_title('Speaker Contribution Analysis')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\n=== Speaker Analysis Summary ===\")\n",
    "    print(f\"Total speakers: {speaker_analysis['total_speakers']}\")\n",
    "    for speaker_id, info in speakers.items():\n",
    "        print(f\"\\nSpeaker {speaker_id}:\")\n",
    "        print(f\"  Segments: {len(info['segments'])}\")\n",
    "        print(f\"  Word count: {info['word_count']}\")\n",
    "\n",
    "def analyze_audio_effects(insights: Dict) -> Dict:\n",
    "    \"\"\"Analyze audio effects and characteristics.\"\"\"\n",
    "    if 'videos' not in insights or len(insights['videos']) == 0:\n",
    "        return {}\n",
    "    \n",
    "    video_insights = insights['videos'][0]['insights']\n",
    "    \n",
    "    audio_analysis = {\n",
    "        \"silence_segments\": [],\n",
    "        \"noise_segments\": [],\n",
    "        \"music_detected\": False\n",
    "    }\n",
    "    \n",
    "    # Check for audio effects in labels\n",
    "    if 'labels' in video_insights:\n",
    "        for label in video_insights['labels']:\n",
    "            label_name = label['name'].lower()\n",
    "            \n",
    "            if 'music' in label_name or 'song' in label_name:\n",
    "                audio_analysis['music_detected'] = True\n",
    "    \n",
    "    return audio_analysis\n",
    "\n",
    "# Example usage\n",
    "print(\"\\n=== Advanced Audio Analysis ===\")\n",
    "print(\"Capabilities:\")\n",
    "print(\"  - Speaker diarization (who spoke when)\")\n",
    "print(\"  - Speaker identification\")\n",
    "print(\"  - Audio effects detection\")\n",
    "print(\"  - Music detection\")\n",
    "print(\"  - Silence detection\")\n",
    "print(\"  - Voice emotion analysis\")\n",
    "print(\"\\nApplications:\")\n",
    "print(\"  - Meeting transcription with speaker labels\")\n",
    "print(\"  - Podcast analysis\")\n",
    "print(\"  - Interview processing\")\n",
    "print(\"  - Multi-speaker content indexing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Scene and Shot Detection\n",
    "\n",
    "Identify scene changes and extract keyframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_scenes_and_shots(insights: Dict) -> Dict:\n",
    "    \"\"\"Extract detailed scene and shot information.\"\"\"\n",
    "    if 'videos' not in insights or len(insights['videos']) == 0:\n",
    "        return {}\n",
    "    \n",
    "    video_insights = insights['videos'][0]['insights']\n",
    "    \n",
    "    scene_data = {\n",
    "        \"scenes\": [],\n",
    "        \"shots\": [],\n",
    "        \"keyframes\": []\n",
    "    }\n",
    "    \n",
    "    # Extract scenes\n",
    "    if 'scenes' in video_insights:\n",
    "        for scene in video_insights['scenes']:\n",
    "            scene_info = {\n",
    "                'id': scene['id'],\n",
    "                'instances': scene.get('instances', [])\n",
    "            }\n",
    "            scene_data['scenes'].append(scene_info)\n",
    "    \n",
    "    # Extract shots\n",
    "    if 'shots' in video_insights:\n",
    "        for shot in video_insights['shots']:\n",
    "            shot_info = {\n",
    "                'id': shot['id'],\n",
    "                'instances': shot.get('instances', []),\n",
    "                'tags': shot.get('tags', [])\n",
    "            }\n",
    "            scene_data['shots'].append(shot_info)\n",
    "    \n",
    "    # Extract keyframes\n",
    "    if 'keyFrames' in video_insights:\n",
    "        for keyframe in video_insights['keyFrames']:\n",
    "            for instance in keyframe.get('instances', []):\n",
    "                scene_data['keyframes'].append({\n",
    "                    'id': keyframe['id'],\n",
    "                    'thumbnail_id': instance.get('thumbnailId'),\n",
    "                    'timestamp': instance.get('start')\n",
    "                })\n",
    "    \n",
    "    return scene_data\n",
    "\n",
    "def get_thumbnail_url(video_id: str, thumbnail_id: str, \n",
    "                     access_token: str) -> str:\n",
    "    \"\"\"Get URL for a specific thumbnail.\"\"\"\n",
    "    return f\"{API_BASE_URL}/{VIDEO_INDEXER_LOCATION}/Accounts/{VIDEO_INDEXER_ACCOUNT_ID}/Videos/{video_id}/Thumbnails/{thumbnail_id}?accessToken={access_token}\"\n",
    "\n",
    "def visualize_scenes(scene_data: Dict):\n",
    "    \"\"\"Visualize scene distribution.\"\"\"\n",
    "    scenes = scene_data.get('scenes', [])\n",
    "    \n",
    "    if not scenes:\n",
    "        print(\"No scene data available\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n=== Scene Analysis ===\")\n",
    "    print(f\"Total scenes: {len(scenes)}\")\n",
    "    print(f\"Total shots: {len(scene_data.get('shots', []))}\")\n",
    "    print(f\"Keyframes extracted: {len(scene_data.get('keyframes', []))}\")\n",
    "    \n",
    "    # Calculate scene durations\n",
    "    scene_durations = []\n",
    "    for scene in scenes:\n",
    "        if scene['instances']:\n",
    "            for instance in scene['instances']:\n",
    "                # Parse timestamps (format: HH:MM:SS.mmm)\n",
    "                start = instance.get('start', '0')\n",
    "                end = instance.get('end', '0')\n",
    "                # Simplified - would need proper time parsing\n",
    "                scene_durations.append(1)  # Placeholder\n",
    "    \n",
    "    if scene_durations:\n",
    "        print(f\"\\nScene Statistics:\")\n",
    "        print(f\"  Average scene length: {sum(scene_durations)/len(scene_durations):.2f}s\")\n",
    "        print(f\"  Shortest scene: {min(scene_durations):.2f}s\")\n",
    "        print(f\"  Longest scene: {max(scene_durations):.2f}s\")\n",
    "\n",
    "# Example usage\n",
    "print(\"\\n=== Scene and Shot Detection ===\")\n",
    "print(\"Features:\")\n",
    "print(\"  - Automatic scene boundary detection\")\n",
    "print(\"  - Shot segmentation\")\n",
    "print(\"  - Keyframe extraction\")\n",
    "print(\"  - Scene tagging and classification\")\n",
    "print(\"\\nApplications:\")\n",
    "print(\"  - Video editing assistance\")\n",
    "print(\"  - Content summarization\")\n",
    "print(\"  - Thumbnail generation\")\n",
    "print(\"  - Scene search and navigation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batch Video Processing\n",
    "\n",
    "Process multiple videos efficiently with batch operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def upload_video_batch(video_files: List[str], access_token: str, \n",
    "                       max_concurrent: int = 3) -> List[Dict]:\n",
    "    \"\"\"Upload multiple videos in parallel.\"\"\"\n",
    "    \n",
    "    def upload_single(video_path: str) -> Dict:\n",
    "        \"\"\"Upload a single video.\"\"\"\n",
    "        video_name = Path(video_path).stem\n",
    "        \n",
    "        url = f\"{API_BASE_URL}/{VIDEO_INDEXER_LOCATION}/Accounts/{VIDEO_INDEXER_ACCOUNT_ID}/Videos\"\n",
    "        params = {\n",
    "            \"accessToken\": access_token,\n",
    "            \"name\": video_name,\n",
    "            \"privacy\": \"Private\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            with open(video_path, \"rb\") as f:\n",
    "                files = {\"file\": f}\n",
    "                response = requests.post(url, params=params, files=files)\n",
    "                response.raise_for_status()\n",
    "                result = response.json()\n",
    "                return {\n",
    "                    \"status\": \"success\",\n",
    "                    \"video_path\": video_path,\n",
    "                    \"video_id\": result['id'],\n",
    "                    \"name\": video_name\n",
    "                }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"video_path\": video_path,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "    \n",
    "    print(f\"Uploading {len(video_files)} videos...\")\n",
    "    results = []\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_concurrent) as executor:\n",
    "        future_to_video = {executor.submit(upload_single, vf): vf for vf in video_files}\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(future_to_video):\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "            \n",
    "            if result['status'] == 'success':\n",
    "                print(f\"✓ {result['name']}: {result['video_id']}\")\n",
    "            else:\n",
    "                print(f\"✗ {result['video_path']}: {result['error']}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def monitor_batch_indexing(video_ids: List[str], access_token: str, \n",
    "                          check_interval: int = 30) -> Dict[str, str]:\n",
    "    \"\"\"Monitor indexing status for multiple videos.\"\"\"\n",
    "    statuses = {vid: \"Uploaded\" for vid in video_ids}\n",
    "    \n",
    "    while True:\n",
    "        all_complete = True\n",
    "        \n",
    "        for video_id in video_ids:\n",
    "            if statuses[video_id] not in ['Processed', 'Failed']:\n",
    "                url = f\"{API_BASE_URL}/{VIDEO_INDEXER_LOCATION}/Accounts/{VIDEO_INDEXER_ACCOUNT_ID}/Videos/{video_id}/Index\"\n",
    "                params = {\"accessToken\": access_token}\n",
    "                \n",
    "                try:\n",
    "                    response = requests.get(url, params=params)\n",
    "                    response.raise_for_status()\n",
    "                    result = response.json()\n",
    "                    statuses[video_id] = result.get('state', 'Unknown')\n",
    "                except:\n",
    "                    statuses[video_id] = 'Error'\n",
    "                \n",
    "                if statuses[video_id] not in ['Processed', 'Failed']:\n",
    "                    all_complete = False\n",
    "        \n",
    "        # Print status update\n",
    "        print(f\"\\nBatch Status:\")\n",
    "        for vid, status in statuses.items():\n",
    "            print(f\"  {vid[:8]}...: {status}\")\n",
    "        \n",
    "        if all_complete:\n",
    "            break\n",
    "        \n",
    "        time.sleep(check_interval)\n",
    "    \n",
    "    return statuses\n",
    "\n",
    "# Example usage\n",
    "print(\"\\n=== Batch Video Processing ===\")\n",
    "print(\"Benefits:\")\n",
    "print(\"  - Process multiple videos simultaneously\")\n",
    "print(\"  - Reduce total processing time\")\n",
    "print(\"  - Centralized monitoring\")\n",
    "print(\"  - Bulk insights extraction\")\n",
    "print(\"\\nWorkflow:\")\n",
    "print(\"  1. Upload videos in parallel\")\n",
    "print(\"  2. Monitor indexing progress\")\n",
    "print(\"  3. Collect insights from all videos\")\n",
    "print(\"  4. Perform comparative analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Custom Language Models\n",
    "\n",
    "Create custom language models for domain-specific terminology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_language_model(model_name: str, language: str, \n",
    "                         access_token: str) -> Dict:\n",
    "    \"\"\"Create a custom language model.\"\"\"\n",
    "    url = f\"{API_BASE_URL}/{VIDEO_INDEXER_LOCATION}/Accounts/{VIDEO_INDEXER_ACCOUNT_ID}/Customization/Language\"\n",
    "    \n",
    "    params = {\n",
    "        \"accessToken\": access_token,\n",
    "        \"modelName\": model_name,\n",
    "        \"language\": language\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    model = response.json()\n",
    "    print(f\"✓ Language model created: {model_name}\")\n",
    "    print(f\"  Model ID: {model['id']}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def upload_language_data(model_id: str, training_text: str, \n",
    "                        access_token: str):\n",
    "    \"\"\"Upload training data for language model.\"\"\"\n",
    "    url = f\"{API_BASE_URL}/{VIDEO_INDEXER_LOCATION}/Accounts/{VIDEO_INDEXER_ACCOUNT_ID}/Customization/Language/{model_id}/Data\"\n",
    "    \n",
    "    params = {\"accessToken\": access_token}\n",
    "    \n",
    "    # Training text should be in proper format\n",
    "    files = {\"file\": (\"training.txt\", training_text, \"text/plain\")}\n",
    "    \n",
    "    response = requests.post(url, params=params, files=files)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    print(\"✓ Language training data uploaded\")\n",
    "\n",
    "# Example usage\n",
    "print(\"\\n=== Custom Language Models ===\")\n",
    "print(\"Use cases:\")\n",
    "print(\"  - Industry-specific terminology\")\n",
    "print(\"  - Medical/legal vocabulary\")\n",
    "print(\"  - Company-specific jargon\")\n",
    "print(\"  - Regional dialects\")\n",
    "print(\"  - Technical documentation\")\n",
    "print(\"\\nProcess:\")\n",
    "print(\"  1. Create language model for specific language\")\n",
    "print(\"  2. Upload training text with domain terminology\")\n",
    "print(\"  3. Train the model\")\n",
    "print(\"  4. Use model when indexing videos for improved transcription\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Video Clipping and Editing\n",
    "\n",
    "Create clips and highlights from indexed videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_video_clip(video_id: str, start_time: str, end_time: str,\n",
    "                     access_token: str) -> Dict:\n",
    "    \"\"\"Create a clip from an indexed video.\n",
    "    \n",
    "    Args:\n",
    "        video_id: The video ID\n",
    "        start_time: Start time in format \"HH:MM:SS\"\n",
    "        end_time: End time in format \"HH:MM:SS\"\n",
    "        access_token: Access token\n",
    "    \"\"\"\n",
    "    # Note: Actual clip creation might require different API endpoint\n",
    "    # This is a simplified example\n",
    "    \n",
    "    clip_info = {\n",
    "        \"video_id\": video_id,\n",
    "        \"start_time\": start_time,\n",
    "        \"end_time\": end_time\n",
    "    }\n",
    "    \n",
    "    print(f\"Clip created: {start_time} to {end_time}\")\n",
    "    return clip_info\n",
    "\n",
    "def create_highlights_from_insights(insights: Dict, \n",
    "                                   criteria: str = \"keywords\") -> List[Dict]:\n",
    "    \"\"\"Create highlight clips based on insights.\"\"\"\n",
    "    if 'videos' not in insights or len(insights['videos']) == 0:\n",
    "        return []\n",
    "    \n",
    "    video_insights = insights['videos'][0]['insights']\n",
    "    highlights = []\n",
    "    \n",
    "    if criteria == \"keywords\":\n",
    "        # Create highlights around top keywords\n",
    "        if 'keywords' in video_insights:\n",
    "            top_keywords = sorted(\n",
    "                video_insights['keywords'],\n",
    "                key=lambda x: x.get('confidence', 0),\n",
    "                reverse=True\n",
    "            )[:5]\n",
    "            \n",
    "            for keyword in top_keywords:\n",
    "                for appearance in keyword.get('appearances', []):\n",
    "                    highlights.append({\n",
    "                        'type': 'keyword',\n",
    "                        'keyword': keyword['name'],\n",
    "                        'start': appearance.get('startTime'),\n",
    "                        'end': appearance.get('endTime')\n",
    "                    })\n",
    "    \n",
    "    elif criteria == \"sentiment\":\n",
    "        # Create highlights around positive sentiments\n",
    "        if 'sentiments' in video_insights:\n",
    "            for sentiment in video_insights['sentiments']:\n",
    "                if sentiment.get('sentimentType') == 'Positive':\n",
    "                    highlights.append({\n",
    "                        'type': 'sentiment',\n",
    "                        'sentiment': 'Positive',\n",
    "                        'duration': sentiment.get('seenDuration')\n",
    "                    })\n",
    "    \n",
    "    return highlights\n",
    "\n",
    "# Example usage\n",
    "print(\"\\n=== Video Clipping and Editing ===\")\n",
    "print(\"Features:\")\n",
    "print(\"  - Create clips from timestamps\")\n",
    "print(\"  - Auto-generate highlights\")\n",
    "print(\"  - Extract key moments\")\n",
    "print(\"  - Create compilations\")\n",
    "print(\"\\nHighlight criteria:\")\n",
    "print(\"  - Top keywords\")\n",
    "print(\"  - Positive sentiments\")\n",
    "print(\"  - Specific topics\")\n",
    "print(\"  - Face appearances\")\n",
    "print(\"  - Action scenes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Integration with Azure Services\n",
    "\n",
    "Integrate Video Indexer with other Azure services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "def setup_blob_storage_integration() -> Dict:\n",
    "    \"\"\"Setup integration with Azure Blob Storage.\"\"\"\n",
    "    print(\"\\n=== Azure Blob Storage Integration ===\")\n",
    "    print(\"\\nSetup steps:\")\n",
    "    print(\"1. Create Azure Storage account\")\n",
    "    print(\"2. Create container for videos\")\n",
    "    print(\"3. Grant Video Indexer access to storage\")\n",
    "    print(\"4. Configure automatic upload triggers\")\n",
    "    \n",
    "    integration_info = {\n",
    "        \"storage_account\": \"Your storage account\",\n",
    "        \"container\": \"videos\",\n",
    "        \"trigger_type\": \"blob_created\"\n",
    "    }\n",
    "    \n",
    "    return integration_info\n",
    "\n",
    "def setup_logic_apps_workflow() -> Dict:\n",
    "    \"\"\"Setup automated workflow with Azure Logic Apps.\"\"\"\n",
    "    print(\"\\n=== Azure Logic Apps Integration ===\")\n",
    "    print(\"\\nWorkflow example:\")\n",
    "    print(\"1. Trigger: New video uploaded to Blob Storage\")\n",
    "    print(\"2. Action: Upload video to Video Indexer\")\n",
    "    print(\"3. Action: Wait for indexing completion\")\n",
    "    print(\"4. Action: Extract insights\")\n",
    "    print(\"5. Action: Store insights in Cosmos DB\")\n",
    "    print(\"6. Action: Send notification via email/Teams\")\n",
    "    \n",
    "    workflow_info = {\n",
    "        \"trigger\": \"BlobCreated\",\n",
    "        \"actions\": [\n",
    "            \"UploadToVideoIndexer\",\n",
    "            \"WaitForIndexing\",\n",
    "            \"ExtractInsights\",\n",
    "            \"StoreInCosmosDB\",\n",
    "            \"SendNotification\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return workflow_info\n",
    "\n",
    "def setup_azure_functions() -> Dict:\n",
    "    \"\"\"Setup serverless processing with Azure Functions.\"\"\"\n",
    "    print(\"\\n=== Azure Functions Integration ===\")\n",
    "    print(\"\\nFunction examples:\")\n",
    "    print(\"- ProcessVideoTrigger: Triggered by blob upload\")\n",
    "    print(\"- ExtractInsightsFunction: Process indexed videos\")\n",
    "    print(\"- GenerateSummaryFunction: Create video summaries\")\n",
    "    print(\"- NotificationFunction: Send alerts and reports\")\n",
    "    \n",
    "    functions_info = {\n",
    "        \"runtime\": \"Python 3.9\",\n",
    "        \"triggers\": [\"BlobTrigger\", \"HttpTrigger\", \"TimerTrigger\"],\n",
    "        \"bindings\": [\"CosmosDB\", \"Queue\", \"ServiceBus\"]\n",
    "    }\n",
    "    \n",
    "    return functions_info\n",
    "\n",
    "# Example usage\n",
    "print(\"\\n=== Azure Services Integration ===\")\n",
    "print(\"\\nIntegration possibilities:\")\n",
    "print(\"  - Azure Blob Storage: Video storage and triggers\")\n",
    "print(\"  - Azure Logic Apps: Automated workflows\")\n",
    "print(\"  - Azure Functions: Serverless processing\")\n",
    "print(\"  - Azure Cosmos DB: Store insights and metadata\")\n",
    "print(\"  - Azure Cognitive Search: Index and search video content\")\n",
    "print(\"  - Power BI: Analytics and visualization\")\n",
    "print(\"  - Microsoft Teams: Notifications and collaboration\")\n",
    "\n",
    "# Show example setups\n",
    "setup_blob_storage_integration()\n",
    "setup_logic_apps_workflow()\n",
    "setup_azure_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This advanced notebook covered:\n",
    "\n",
    "1. **Custom Brand Models** - Detect company-specific brands and products\n",
    "2. **Custom People Models** - Recognize specific individuals (requires approval)\n",
    "3. **Content Moderation** - Detect inappropriate content for compliance\n",
    "4. **Advanced Audio Analysis** - Speaker diarization and emotion detection\n",
    "5. **Scene & Shot Detection** - Identify scene boundaries and extract keyframes\n",
    "6. **Batch Processing** - Process multiple videos efficiently\n",
    "7. **Custom Language Models** - Improve transcription for domain-specific terms\n",
    "8. **Video Clipping** - Create highlights and clips from insights\n",
    "9. **Azure Integration** - Connect with Storage, Logic Apps, Functions\n",
    "\n",
    "### Production Considerations\n",
    "\n",
    "- **Authentication**: Use managed identities in production\n",
    "- **Rate Limits**: Implement retry logic and backoff\n",
    "- **Error Handling**: Robust error handling and logging\n",
    "- **Monitoring**: Track processing status and costs\n",
    "- **Privacy**: Handle PII and comply with regulations\n",
    "- **Limited Access**: Face recognition requires Microsoft approval\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Build end-to-end video processing pipelines\n",
    "- Implement custom models for your use case\n",
    "- Create automated workflows with Logic Apps\n",
    "- Integrate with your existing Azure infrastructure\n",
    "- Develop custom applications using Video Indexer insights\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Video Indexer API Reference](https://api-portal.videoindexer.ai/)\n",
    "- [Custom Models Documentation](https://learn.microsoft.com/azure/azure-video-indexer/customize-brands-model-overview)\n",
    "- [Limited Access Features](https://learn.microsoft.com/azure/azure-video-indexer/limited-access-features)\n",
    "- [Best Practices](https://learn.microsoft.com/azure/azure-video-indexer/considerations-when-use-at-scale)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
