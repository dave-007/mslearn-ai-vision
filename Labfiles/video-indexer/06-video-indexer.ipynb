{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 06: Azure Video Indexer\n",
    "\n",
    "## Overview\n",
    "Azure Video Indexer is an AI-powered service that extracts rich insights from videos. This notebook demonstrates how to upload videos, extract comprehensive insights including faces, text, keywords, topics, sentiments, transcripts, objects, and scenes.\n",
    "\n",
    "## Topics Covered\n",
    "- Uploading and indexing videos\n",
    "- Extracting video insights (faces, text, keywords, topics, sentiments)\n",
    "- Working with video transcripts\n",
    "- Object and scene detection in videos\n",
    "- Timeline analysis\n",
    "- Using Video Indexer API programmatically\n",
    "- Downloading and processing insights\n",
    "- Creating video highlights and summaries\n",
    "- Facial recognition (requires limited access approval)\n",
    "\n",
    "## Prerequisites\n",
    "- Azure Video Indexer account\n",
    "- API key and account ID\n",
    "- Video file: `responsible_ai.mp4` (included in this directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests python-dotenv pandas matplotlib pillow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML, Video, Markdown\n",
    "\n",
    "# Load configuration\n",
    "load_dotenv('python/.env')\n",
    "\n",
    "# Video Indexer configuration\n",
    "VIDEO_INDEXER_ACCOUNT_ID = os.getenv(\"VIDEO_INDEXER_ACCOUNT_ID\")\n",
    "VIDEO_INDEXER_API_KEY = os.getenv(\"VIDEO_INDEXER_API_KEY\")\n",
    "VIDEO_INDEXER_LOCATION = os.getenv(\"VIDEO_INDEXER_LOCATION\", \"trial\")  # or your region like \"eastus\"\n",
    "\n",
    "# API endpoints\n",
    "API_BASE_URL = f\"https://api.videoindexer.ai\"\n",
    "\n",
    "# Video file\n",
    "VIDEO_FILE = \"responsible_ai.mp4\"\n",
    "\n",
    "if not VIDEO_INDEXER_ACCOUNT_ID or not VIDEO_INDEXER_API_KEY:\n",
    "    print(\"âš  Warning: Video Indexer credentials not found in .env file\")\n",
    "    print(\"Please add VIDEO_INDEXER_ACCOUNT_ID and VIDEO_INDEXER_API_KEY to your .env file\")\n",
    "else:\n",
    "    print(\"âœ“ Video Indexer configuration loaded\")\n",
    "\n",
    "if os.path.exists(VIDEO_FILE):\n",
    "    print(f\"âœ“ Video file found: {VIDEO_FILE}\")\n",
    "else:\n",
    "    print(f\"âš  Video file not found: {VIDEO_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Authentication and Access Token\n",
    "\n",
    "Get an access token to authenticate with the Video Indexer API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_access_token(account_id: str, location: str, api_key: str) -> str:\n",
    "    \"\"\"Get access token for Video Indexer API.\"\"\"\n",
    "    url = f\"{API_BASE_URL}/auth/{location}/Accounts/{account_id}/AccessToken\"\n",
    "    \n",
    "    params = {\n",
    "        \"allowEdit\": \"true\"\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": api_key\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    # Response is a quoted string, remove quotes\n",
    "    token = response.json().strip('\"')\n",
    "    print(\"âœ“ Access token obtained\")\n",
    "    return token\n",
    "\n",
    "# Get access token\n",
    "if VIDEO_INDEXER_ACCOUNT_ID and VIDEO_INDEXER_API_KEY:\n",
    "    try:\n",
    "        access_token = get_access_token(\n",
    "            VIDEO_INDEXER_ACCOUNT_ID,\n",
    "            VIDEO_INDEXER_LOCATION,\n",
    "            VIDEO_INDEXER_API_KEY\n",
    "        )\n",
    "        print(f\"Token length: {len(access_token)} characters\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error obtaining access token: {str(e)}\")\n",
    "        access_token = None\n",
    "else:\n",
    "    access_token = None\n",
    "    print(\"Skipping authentication - credentials not configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Upload and Index Video\n",
    "\n",
    "Upload a video file and start the indexing process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_video(video_path: str, video_name: str, access_token: str, \n",
    "                 location: str, account_id: str, \n",
    "                 privacy: str = \"Private\") -> Dict:\n",
    "    \"\"\"Upload and index a video.\"\"\"\n",
    "    \n",
    "    url = f\"{API_BASE_URL}/{location}/Accounts/{account_id}/Videos\"\n",
    "    \n",
    "    params = {\n",
    "        \"accessToken\": access_token,\n",
    "        \"name\": video_name,\n",
    "        \"privacy\": privacy,\n",
    "        \"description\": \"Video uploaded for analysis\"\n",
    "    }\n",
    "    \n",
    "    # Read video file\n",
    "    with open(video_path, \"rb\") as video_file:\n",
    "        files = {\"file\": video_file}\n",
    "        \n",
    "        print(f\"Uploading video: {video_name}...\")\n",
    "        response = requests.post(url, params=params, files=files)\n",
    "        response.raise_for_status()\n",
    "    \n",
    "    result = response.json()\n",
    "    video_id = result[\"id\"]\n",
    "    \n",
    "    print(f\"âœ“ Video uploaded successfully\")\n",
    "    print(f\"  Video ID: {video_id}\")\n",
    "    print(f\"  Indexing started...\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "def check_indexing_status(video_id: str, access_token: str, \n",
    "                         location: str, account_id: str) -> Dict:\n",
    "    \"\"\"Check the indexing status of a video.\"\"\"\n",
    "    url = f\"{API_BASE_URL}/{location}/Accounts/{account_id}/Videos/{video_id}/Index\"\n",
    "    \n",
    "    params = {\n",
    "        \"accessToken\": access_token\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "def wait_for_indexing(video_id: str, access_token: str, \n",
    "                      location: str, account_id: str, \n",
    "                      max_wait: int = 600) -> Dict:\n",
    "    \"\"\"Wait for video indexing to complete.\"\"\"\n",
    "    print(\"Waiting for indexing to complete...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    while time.time() - start_time < max_wait:\n",
    "        status = check_indexing_status(video_id, access_token, location, account_id)\n",
    "        state = status.get(\"state\")\n",
    "        \n",
    "        if state == \"Processed\":\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"âœ“ Indexing complete! (took {elapsed:.1f}s)\")\n",
    "            return status\n",
    "        elif state == \"Failed\":\n",
    "            print(\"âœ— Indexing failed\")\n",
    "            return status\n",
    "        \n",
    "        print(f\"  Status: {state}... (elapsed: {time.time() - start_time:.1f}s)\")\n",
    "        time.sleep(10)\n",
    "    \n",
    "    print(f\"âš  Timeout after {max_wait}s\")\n",
    "    return check_indexing_status(video_id, access_token, location, account_id)\n",
    "\n",
    "# Example: Upload video\n",
    "print(\"\\n=== Video Upload and Indexing ===\")\n",
    "print(\"This process will:\")\n",
    "print(\"  1. Upload the video to Azure Video Indexer\")\n",
    "print(\"  2. Start automatic indexing\")\n",
    "print(\"  3. Extract insights (may take several minutes)\")\n",
    "print(\"\\nNote: The responsible_ai.mp4 video is about responsible AI practices.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload and index the video (uncomment to run)\n",
    "if access_token and os.path.exists(VIDEO_FILE):\n",
    "    try:\n",
    "        upload_result = upload_video(\n",
    "            VIDEO_FILE,\n",
    "            \"Responsible AI Video\",\n",
    "            access_token,\n",
    "            VIDEO_INDEXER_LOCATION,\n",
    "            VIDEO_INDEXER_ACCOUNT_ID\n",
    "        )\n",
    "        \n",
    "        video_id = upload_result[\"id\"]\n",
    "        \n",
    "        # Wait for indexing to complete\n",
    "        indexed_video = wait_for_indexing(\n",
    "            video_id,\n",
    "            access_token,\n",
    "            VIDEO_INDEXER_LOCATION,\n",
    "            VIDEO_INDEXER_ACCOUNT_ID\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        video_id = None\n",
    "else:\n",
    "    print(\"Skipping upload - credentials or video file not available\")\n",
    "    video_id = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Video Insights\n",
    "\n",
    "Once indexing is complete, extract comprehensive insights from the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_insights(video_id: str, access_token: str, \n",
    "                       location: str, account_id: str) -> Dict:\n",
    "    \"\"\"Get comprehensive insights for an indexed video.\"\"\"\n",
    "    url = f\"{API_BASE_URL}/{location}/Accounts/{account_id}/Videos/{video_id}/Index\"\n",
    "    \n",
    "    params = {\n",
    "        \"accessToken\": access_token\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, params=params)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    return response.json()\n",
    "\n",
    "def display_video_summary(insights: Dict):\n",
    "    \"\"\"Display a summary of video insights.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"VIDEO INSIGHTS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"\\nðŸ“¹ Video: {insights.get('name', 'N/A')}\")\n",
    "    print(f\"Duration: {insights.get('durationInSeconds', 0)} seconds\")\n",
    "    print(f\"State: {insights.get('state', 'N/A')}\")\n",
    "    \n",
    "    # Get insights from videos array\n",
    "    if 'videos' in insights and len(insights['videos']) > 0:\n",
    "        video_insights = insights['videos'][0]['insights']\n",
    "        \n",
    "        # Transcript\n",
    "        if 'transcript' in video_insights:\n",
    "            print(f\"\\nðŸ“ Transcript: {len(video_insights['transcript'])} segments\")\n",
    "        \n",
    "        # Keywords\n",
    "        if 'keywords' in video_insights:\n",
    "            keywords = video_insights['keywords']\n",
    "            print(f\"\\nðŸ”‘ Keywords ({len(keywords)}):\")\n",
    "            for kw in keywords[:10]:\n",
    "                print(f\"  - {kw['name']} (confidence: {kw.get('confidence', 0):.2f})\")\n",
    "        \n",
    "        # Topics\n",
    "        if 'topics' in video_insights:\n",
    "            topics = video_insights['topics']\n",
    "            print(f\"\\nðŸ“š Topics ({len(topics)}):\")\n",
    "            for topic in topics[:5]:\n",
    "                print(f\"  - {topic['name']} (confidence: {topic.get('confidence', 0):.2f})\")\n",
    "        \n",
    "        # Faces (Note: May require limited access approval)\n",
    "        if 'faces' in video_insights:\n",
    "            faces = video_insights['faces']\n",
    "            print(f\"\\nðŸ‘¤ Faces detected: {len(faces)}\")\n",
    "            if len(faces) > 0:\n",
    "                print(\"  Note: Facial recognition requires Limited Access approval\")\n",
    "        \n",
    "        # Labels (visual content)\n",
    "        if 'labels' in video_insights:\n",
    "            labels = video_insights['labels']\n",
    "            print(f\"\\nðŸ·ï¸ Visual Labels ({len(labels)}):\")\n",
    "            for label in labels[:10]:\n",
    "                print(f\"  - {label['name']} (appears {len(label.get('appearances', []))} times)\")\n",
    "        \n",
    "        # Sentiments\n",
    "        if 'sentiments' in video_insights:\n",
    "            sentiments = video_insights['sentiments']\n",
    "            print(f\"\\nðŸ˜Š Sentiments: {len(sentiments)} segments analyzed\")\n",
    "            \n",
    "            # Count sentiment types\n",
    "            sentiment_counts = {}\n",
    "            for sentiment in sentiments:\n",
    "                s_type = sentiment.get('sentimentType', 'Unknown')\n",
    "                sentiment_counts[s_type] = sentiment_counts.get(s_type, 0) + 1\n",
    "            \n",
    "            for s_type, count in sentiment_counts.items():\n",
    "                print(f\"  - {s_type}: {count} segments\")\n",
    "        \n",
    "        # Brands\n",
    "        if 'brands' in video_insights:\n",
    "            brands = video_insights['brands']\n",
    "            if len(brands) > 0:\n",
    "                print(f\"\\nðŸ¢ Brands detected: {len(brands)}\")\n",
    "                for brand in brands[:5]:\n",
    "                    print(f\"  - {brand['name']}\")\n",
    "        \n",
    "        # Named locations\n",
    "        if 'namedLocations' in video_insights:\n",
    "            locations = video_insights['namedLocations']\n",
    "            if len(locations) > 0:\n",
    "                print(f\"\\nðŸ“ Locations mentioned: {len(locations)}\")\n",
    "                for loc in locations[:5]:\n",
    "                    print(f\"  - {loc['name']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Get and display insights\n",
    "if video_id and access_token:\n",
    "    try:\n",
    "        insights = get_video_insights(\n",
    "            video_id,\n",
    "            access_token,\n",
    "            VIDEO_INDEXER_LOCATION,\n",
    "            VIDEO_INDEXER_ACCOUNT_ID\n",
    "        )\n",
    "        display_video_summary(insights)\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting insights: {str(e)}\")\n",
    "        insights = None\n",
    "else:\n",
    "    print(\"Skipping insights extraction - video not indexed\")\n",
    "    insights = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract and Display Transcript\n",
    "\n",
    "Get the full transcript with timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_transcript(insights: Dict) -> List[Dict]:\n",
    "    \"\"\"Extract transcript with timestamps.\"\"\"\n",
    "    if 'videos' not in insights or len(insights['videos']) == 0:\n",
    "        return []\n",
    "    \n",
    "    video_insights = insights['videos'][0]['insights']\n",
    "    \n",
    "    if 'transcript' not in video_insights:\n",
    "        return []\n",
    "    \n",
    "    transcript_segments = []\n",
    "    \n",
    "    for segment in video_insights['transcript']:\n",
    "        transcript_segments.append({\n",
    "            \"id\": segment.get('id'),\n",
    "            \"text\": segment.get('text'),\n",
    "            \"confidence\": segment.get('confidence'),\n",
    "            \"speaker_id\": segment.get('speakerId'),\n",
    "            \"start\": segment.get('start'),\n",
    "            \"end\": segment.get('end')\n",
    "        })\n",
    "    \n",
    "    return transcript_segments\n",
    "\n",
    "def display_transcript(transcript: List[Dict], max_lines: int = 20):\n",
    "    \"\"\"Display transcript in readable format.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"VIDEO TRANSCRIPT\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    for i, segment in enumerate(transcript[:max_lines]):\n",
    "        timestamp = segment.get('start', 'N/A')\n",
    "        text = segment.get('text', '')\n",
    "        confidence = segment.get('confidence', 0)\n",
    "        \n",
    "        print(f\"[{timestamp}] {text}\")\n",
    "        print(f\"  (confidence: {confidence:.2f})\\n\")\n",
    "    \n",
    "    if len(transcript) > max_lines:\n",
    "        print(f\"... and {len(transcript) - max_lines} more segments\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "def get_full_transcript_text(transcript: List[Dict]) -> str:\n",
    "    \"\"\"Get full transcript as continuous text.\"\"\"\n",
    "    return \" \".join([seg.get('text', '') for seg in transcript])\n",
    "\n",
    "# Extract and display transcript\n",
    "if insights:\n",
    "    transcript = extract_transcript(insights)\n",
    "    if transcript:\n",
    "        display_transcript(transcript)\n",
    "        \n",
    "        # Get full text\n",
    "        full_text = get_full_transcript_text(transcript)\n",
    "        print(f\"\\nFull transcript length: {len(full_text)} characters\")\n",
    "        print(f\"Total segments: {len(transcript)}\")\n",
    "    else:\n",
    "        print(\"No transcript available\")\n",
    "else:\n",
    "    print(\"No insights available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Timeline Analysis\n",
    "\n",
    "Analyze when different insights appear throughout the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_timeline(insights: Dict) -> Dict:\n",
    "    \"\"\"Analyze insights timeline.\"\"\"\n",
    "    if 'videos' not in insights or len(insights['videos']) == 0:\n",
    "        return {}\n",
    "    \n",
    "    video_insights = insights['videos'][0]['insights']\n",
    "    duration = insights.get('durationInSeconds', 0)\n",
    "    \n",
    "    timeline = {\n",
    "        \"duration\": duration,\n",
    "        \"keyword_timeline\": [],\n",
    "        \"sentiment_timeline\": [],\n",
    "        \"label_timeline\": []\n",
    "    }\n",
    "    \n",
    "    # Keywords over time\n",
    "    if 'keywords' in video_insights:\n",
    "        for keyword in video_insights['keywords']:\n",
    "            for appearance in keyword.get('appearances', []):\n",
    "                timeline['keyword_timeline'].append({\n",
    "                    'keyword': keyword['name'],\n",
    "                    'start': appearance.get('startSeconds', 0),\n",
    "                    'end': appearance.get('endSeconds', 0)\n",
    "                })\n",
    "    \n",
    "    # Sentiments over time\n",
    "    if 'sentiments' in video_insights:\n",
    "        for sentiment in video_insights['sentiments']:\n",
    "            timeline['sentiment_timeline'].append({\n",
    "                'sentiment': sentiment.get('sentimentType'),\n",
    "                'start': sentiment.get('seenDuration', 0)\n",
    "            })\n",
    "    \n",
    "    # Labels over time\n",
    "    if 'labels' in video_insights:\n",
    "        for label in video_insights['labels']:\n",
    "            for appearance in label.get('appearances', []):\n",
    "                timeline['label_timeline'].append({\n",
    "                    'label': label['name'],\n",
    "                    'start': appearance.get('startSeconds', 0),\n",
    "                    'end': appearance.get('endSeconds', 0)\n",
    "                })\n",
    "    \n",
    "    return timeline\n",
    "\n",
    "def visualize_sentiment_timeline(timeline: Dict):\n",
    "    \"\"\"Visualize sentiment changes over time.\"\"\"\n",
    "    if not timeline.get('sentiment_timeline'):\n",
    "        print(\"No sentiment data available\")\n",
    "        return\n",
    "    \n",
    "    sentiments = timeline['sentiment_timeline']\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    \n",
    "    sentiment_colors = {\n",
    "        'Positive': 'green',\n",
    "        'Neutral': 'gray',\n",
    "        'Negative': 'red'\n",
    "    }\n",
    "    \n",
    "    for sentiment in sentiments:\n",
    "        s_type = sentiment['sentiment']\n",
    "        start = sentiment['start']\n",
    "        color = sentiment_colors.get(s_type, 'blue')\n",
    "        \n",
    "        ax.scatter(start, 1, c=color, s=100, alpha=0.6, label=s_type)\n",
    "    \n",
    "    # Remove duplicate labels\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    by_label = dict(zip(labels, handles))\n",
    "    ax.legend(by_label.values(), by_label.keys())\n",
    "    \n",
    "    ax.set_xlabel('Time (seconds)')\n",
    "    ax.set_title('Sentiment Analysis Timeline')\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim(0, timeline['duration'])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Analyze and visualize timeline\n",
    "if insights:\n",
    "    timeline = analyze_timeline(insights)\n",
    "    \n",
    "    print(f\"\\n=== Timeline Analysis ===\")\n",
    "    print(f\"Video duration: {timeline['duration']} seconds\")\n",
    "    print(f\"Keywords tracked: {len(timeline['keyword_timeline'])} occurrences\")\n",
    "    print(f\"Sentiment changes: {len(timeline['sentiment_timeline'])}\")\n",
    "    print(f\"Visual labels: {len(timeline['label_timeline'])} occurrences\")\n",
    "    \n",
    "    # Visualize sentiments\n",
    "    visualize_sentiment_timeline(timeline)\n",
    "else:\n",
    "    print(\"No insights available for timeline analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Object and Scene Detection\n",
    "\n",
    "Extract detected objects and scenes from the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_objects_and_scenes(insights: Dict) -> Dict:\n",
    "    \"\"\"Extract detected objects and scenes.\"\"\"\n",
    "    if 'videos' not in insights or len(insights['videos']) == 0:\n",
    "        return {\"labels\": [], \"scenes\": []}\n",
    "    \n",
    "    video_insights = insights['videos'][0]['insights']\n",
    "    \n",
    "    # Labels represent visual objects\n",
    "    labels = []\n",
    "    if 'labels' in video_insights:\n",
    "        for label in video_insights['labels']:\n",
    "            labels.append({\n",
    "                'name': label['name'],\n",
    "                'id': label['id'],\n",
    "                'appearances': len(label.get('appearances', [])),\n",
    "                'total_duration': sum(\n",
    "                    app.get('endSeconds', 0) - app.get('startSeconds', 0)\n",
    "                    for app in label.get('appearances', [])\n",
    "                )\n",
    "            })\n",
    "    \n",
    "    # Scenes\n",
    "    scenes = []\n",
    "    if 'scenes' in video_insights:\n",
    "        for scene in video_insights['scenes']:\n",
    "            scenes.append({\n",
    "                'id': scene['id'],\n",
    "                'start': scene.get('instances', [{}])[0].get('start'),\n",
    "                'end': scene.get('instances', [{}])[0].get('end')\n",
    "            })\n",
    "    \n",
    "    return {\"labels\": labels, \"scenes\": scenes}\n",
    "\n",
    "def display_top_objects(objects_data: Dict, top_n: int = 15):\n",
    "    \"\"\"Display most frequently appearing objects.\"\"\"\n",
    "    labels = objects_data['labels']\n",
    "    \n",
    "    if not labels:\n",
    "        print(\"No object data available\")\n",
    "        return\n",
    "    \n",
    "    # Sort by total duration\n",
    "    sorted_labels = sorted(labels, key=lambda x: x['total_duration'], reverse=True)\n",
    "    \n",
    "    print(f\"\\n=== Top {top_n} Visual Objects ===\")\n",
    "    print(f\"{'Object':<30} {'Appearances':<15} {'Total Duration (s)'}\")\n",
    "    print(\"-\" * 65)\n",
    "    \n",
    "    for label in sorted_labels[:top_n]:\n",
    "        print(f\"{label['name']:<30} {label['appearances']:<15} {label['total_duration']:.2f}\")\n",
    "    \n",
    "    # Visualize top objects\n",
    "    if len(sorted_labels) > 0:\n",
    "        top_labels = sorted_labels[:top_n]\n",
    "        names = [l['name'] for l in top_labels]\n",
    "        durations = [l['total_duration'] for l in top_labels]\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        ax.barh(names, durations, color='steelblue')\n",
    "        ax.set_xlabel('Total Duration (seconds)')\n",
    "        ax.set_title('Top Visual Objects by Duration')\n",
    "        ax.invert_yaxis()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Extract and display objects\n",
    "if insights:\n",
    "    objects_data = extract_objects_and_scenes(insights)\n",
    "    display_top_objects(objects_data)\n",
    "    print(f\"\\nTotal scenes detected: {len(objects_data['scenes'])}\")\n",
    "else:\n",
    "    print(\"No insights available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Video Summary\n",
    "\n",
    "Generate a comprehensive summary of the video content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_video_summary(insights: Dict, transcript: List[Dict]) -> str:\n",
    "    \"\"\"Generate a comprehensive video summary.\"\"\"\n",
    "    if 'videos' not in insights or len(insights['videos']) == 0:\n",
    "        return \"No insights available\"\n",
    "    \n",
    "    video_insights = insights['videos'][0]['insights']\n",
    "    \n",
    "    summary = []\n",
    "    summary.append(\"# Video Analysis Summary\")\n",
    "    summary.append(\"\\n## Basic Information\")\n",
    "    summary.append(f\"- **Title**: {insights.get('name', 'N/A')}\")\n",
    "    summary.append(f\"- **Duration**: {insights.get('durationInSeconds', 0)} seconds\")\n",
    "    summary.append(f\"- **State**: {insights.get('state', 'N/A')}\")\n",
    "    \n",
    "    # Key topics\n",
    "    if 'topics' in video_insights:\n",
    "        summary.append(\"\\n## Main Topics\")\n",
    "        for topic in video_insights['topics'][:5]:\n",
    "            summary.append(f\"- {topic['name']}\")\n",
    "    \n",
    "    # Keywords\n",
    "    if 'keywords' in video_insights:\n",
    "        summary.append(\"\\n## Key Terms\")\n",
    "        keywords = [kw['name'] for kw in video_insights['keywords'][:10]]\n",
    "        summary.append(\", \".join(keywords))\n",
    "    \n",
    "    # Sentiment overview\n",
    "    if 'sentiments' in video_insights:\n",
    "        sentiment_counts = {}\n",
    "        for sentiment in video_insights['sentiments']:\n",
    "            s_type = sentiment.get('sentimentType', 'Unknown')\n",
    "            sentiment_counts[s_type] = sentiment_counts.get(s_type, 0) + 1\n",
    "        \n",
    "        summary.append(\"\\n## Sentiment Analysis\")\n",
    "        for s_type, count in sentiment_counts.items():\n",
    "            summary.append(f\"- {s_type}: {count} segments\")\n",
    "    \n",
    "    # Transcript excerpt\n",
    "    if transcript:\n",
    "        summary.append(\"\\n## Transcript Excerpt\")\n",
    "        excerpt = \" \".join([seg['text'] for seg in transcript[:5]])\n",
    "        summary.append(excerpt[:500] + \"...\")\n",
    "    \n",
    "    # Visual content\n",
    "    if 'labels' in video_insights:\n",
    "        summary.append(\"\\n## Visual Content\")\n",
    "        top_labels = sorted(\n",
    "            video_insights['labels'],\n",
    "            key=lambda x: len(x.get('appearances', [])),\n",
    "            reverse=True\n",
    "        )[:10]\n",
    "        labels_list = [label['name'] for label in top_labels]\n",
    "        summary.append(\", \".join(labels_list))\n",
    "    \n",
    "    return \"\\n\".join(summary)\n",
    "\n",
    "# Generate and display summary\n",
    "if insights and transcript:\n",
    "    summary = generate_video_summary(insights, transcript)\n",
    "    display(Markdown(summary))\n",
    "else:\n",
    "    print(\"Cannot generate summary - insights or transcript not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Download Insights JSON\n",
    "\n",
    "Save complete insights data for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_insights_to_file(insights: Dict, filename: str = \"video_insights.json\"):\n",
    "    \"\"\"Save insights to a JSON file.\"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(insights, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    file_size = os.path.getsize(filename)\n",
    "    print(f\"âœ“ Insights saved to {filename}\")\n",
    "    print(f\"  File size: {file_size:,} bytes\")\n",
    "    \n",
    "    return filename\n",
    "\n",
    "# Save insights\n",
    "if insights:\n",
    "    output_file = save_insights_to_file(insights, \"responsible_ai_insights.json\")\n",
    "else:\n",
    "    print(\"No insights to save\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Search Within Video\n",
    "\n",
    "Search for specific content within the video using the insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_video_content(insights: Dict, transcript: List[Dict], \n",
    "                        query: str) -> List[Dict]:\n",
    "    \"\"\"Search for content within the video.\"\"\"\n",
    "    results = []\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Search transcript\n",
    "    for segment in transcript:\n",
    "        if query_lower in segment['text'].lower():\n",
    "            results.append({\n",
    "                'type': 'transcript',\n",
    "                'timestamp': segment['start'],\n",
    "                'text': segment['text'],\n",
    "                'confidence': segment.get('confidence', 0)\n",
    "            })\n",
    "    \n",
    "    # Search keywords\n",
    "    if 'videos' in insights and len(insights['videos']) > 0:\n",
    "        video_insights = insights['videos'][0]['insights']\n",
    "        \n",
    "        if 'keywords' in video_insights:\n",
    "            for keyword in video_insights['keywords']:\n",
    "                if query_lower in keyword['name'].lower():\n",
    "                    for appearance in keyword.get('appearances', []):\n",
    "                        results.append({\n",
    "                            'type': 'keyword',\n",
    "                            'timestamp': appearance.get('startTime'),\n",
    "                            'text': keyword['name'],\n",
    "                            'confidence': keyword.get('confidence', 0)\n",
    "                        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "def display_search_results(results: List[Dict], max_results: int = 10):\n",
    "    \"\"\"Display search results.\"\"\"\n",
    "    if not results:\n",
    "        print(\"No results found\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nFound {len(results)} results:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for i, result in enumerate(results[:max_results]):\n",
    "        print(f\"\\n{i+1}. [{result['timestamp']}] ({result['type']})\")\n",
    "        print(f\"   {result['text']}\")\n",
    "        print(f\"   Confidence: {result.get('confidence', 0):.2f}\")\n",
    "    \n",
    "    if len(results) > max_results:\n",
    "        print(f\"\\n... and {len(results) - max_results} more results\")\n",
    "\n",
    "# Example search\n",
    "if insights and transcript:\n",
    "    search_query = \"AI\"  # Change this to search for different terms\n",
    "    print(f\"\\n=== Searching for: '{search_query}' ===\")\n",
    "    search_results = search_video_content(insights, transcript, search_query)\n",
    "    display_search_results(search_results)\n",
    "else:\n",
    "    print(\"No data available for search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated how to use Azure Video Indexer to:\n",
    "\n",
    "1. **Upload and Index Videos** - Upload videos and extract comprehensive insights\n",
    "2. **Extract Insights** - Get faces, keywords, topics, sentiments, and more\n",
    "3. **Work with Transcripts** - Access timestamped transcriptions\n",
    "4. **Timeline Analysis** - Track when insights appear throughout the video\n",
    "5. **Object Detection** - Identify and track visual objects and scenes\n",
    "6. **Generate Summaries** - Create comprehensive video summaries\n",
    "7. **Save Insights** - Export insights for further processing\n",
    "8. **Search Content** - Search within video content\n",
    "\n",
    "### Important Notes\n",
    "\n",
    "- **Facial Recognition**: Requires Limited Access approval from Microsoft\n",
    "- **Processing Time**: Video indexing can take several minutes depending on video length\n",
    "- **API Limits**: Be aware of rate limits and quotas for your subscription\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore the Advanced Video Indexer notebook for more features\n",
    "- Build custom models for brands and people\n",
    "- Integrate with other Azure services\n",
    "- Create automated video analysis pipelines\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Azure Video Indexer Documentation](https://learn.microsoft.com/azure/azure-video-indexer/)\n",
    "- [Video Indexer API Reference](https://api-portal.videoindexer.ai/)\n",
    "- [Video Indexer Developer Portal](https://www.videoindexer.ai/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
