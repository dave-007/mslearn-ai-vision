{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 02: Optical Character Recognition (OCR) with Azure AI Vision\n",
    "\n",
    "## Overview\n",
    "Optical Character Recognition (OCR) enables you to extract text from images. Azure AI Vision's Read API uses advanced AI models to read printed and handwritten text from images and documents. In this lab, you'll:\n",
    "- Extract text from images using the Read API\n",
    "- Process and display detected text with line and word boundaries\n",
    "- Visualize text detection results with bounding boxes\n",
    "\n",
    "## Prerequisites\n",
    "- An Azure subscription with an Azure AI Vision resource\n",
    "- The endpoint and key for your Azure AI Vision resource\n",
    "\n",
    "## Learning Objectives\n",
    "- Use the Read API for text extraction from images\n",
    "- Process OCR results including text blocks, lines, and words\n",
    "- Visualize detected text with bounding polygons\n",
    "- Handle different image types and text orientations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install python-dotenv azure-ai-vision-imageanalysis==1.0.0 matplotlib pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "from PIL import Image, ImageDraw\n",
    "from matplotlib import pyplot as plt\n",
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure Azure AI Vision Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from .env file\n",
    "load_dotenv('python/read-text/.env')\n",
    "\n",
    "ai_endpoint = os.getenv('AI_SERVICE_ENDPOINT')\n",
    "ai_key = os.getenv('AI_SERVICE_KEY')\n",
    "\n",
    "# Validate credentials\n",
    "if not ai_endpoint or not ai_key or 'your_' in ai_endpoint or 'your_' in ai_key:\n",
    "    print(\"⚠ Warning: Please configure your Azure AI Vision credentials\")\n",
    "else:\n",
    "    print(f\"✓ Endpoint configured: {ai_endpoint[:30]}...\")\n",
    "    print(\"✓ API key loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Authenticate Azure AI Vision Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create authenticated client\n",
    "cv_client = ImageAnalysisClient(\n",
    "    endpoint=ai_endpoint,\n",
    "    credential=AzureKeyCredential(ai_key)\n",
    ")\n",
    "\n",
    "print(\"✓ Azure AI Vision client authenticated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Read Text from an Image\n",
    "\n",
    "Let's use the Read API to extract text from an image. We'll use an image containing the Gettysburg Address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the image to read\n",
    "image_file = 'python/read-text/images/Lincoln.jpg'\n",
    "\n",
    "# Display the image\n",
    "print(f\"Reading text from: {image_file}\")\n",
    "img = Image.open(image_file)\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Image with Text to Extract')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Image size: {img.size[0]}x{img.size[1]} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Extract Text Using Read API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image data\n",
    "with open(image_file, \"rb\") as f:\n",
    "    image_data = f.read()\n",
    "\n",
    "# Call the Read API\n",
    "print(\"\\nExtracting text from image...\")\n",
    "result = cv_client.analyze(\n",
    "    image_data=image_data,\n",
    "    visual_features=[VisualFeatures.READ]\n",
    ")\n",
    "\n",
    "print(\"✓ Text extraction complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Display Extracted Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the extracted text\n",
    "if result.read is not None:\n",
    "    print(\"\\n=== Extracted Text ===\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Iterate through blocks of text\n",
    "    for block in result.read.blocks:\n",
    "        for line in block.lines:\n",
    "            print(line.text)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Display statistics\n",
    "    total_lines = sum(len(block.lines) for block in result.read.blocks)\n",
    "    total_words = sum(len(line.words) for block in result.read.blocks for line in block.lines)\n",
    "    \n",
    "    print(f\"\\nStatistics:\")\n",
    "    print(f\"  Blocks: {len(result.read.blocks)}\")\n",
    "    print(f\"  Lines: {total_lines}\")\n",
    "    print(f\"  Words: {total_words}\")\n",
    "else:\n",
    "    print(\"No text detected in the image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Visualize Text Detection\n",
    "\n",
    "Let's visualize the detected text by drawing bounding boxes around lines and words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Annotate Lines of Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_lines(image_file, detected_text):\n",
    "    \"\"\"\n",
    "    Draw bounding boxes around detected lines of text.\n",
    "    \n",
    "    Args:\n",
    "        image_file: Path to the image file\n",
    "        detected_text: Read result from Azure AI Vision\n",
    "    \"\"\"\n",
    "    print('\\nAnnotating lines of text in image...')\n",
    "    \n",
    "    # Prepare image for drawing\n",
    "    image = Image.open(image_file)\n",
    "    fig = plt.figure(figsize=(image.width/100, image.height/100))\n",
    "    plt.axis('off')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    color = 'cyan'\n",
    "    \n",
    "    for block in detected_text.blocks:\n",
    "        for line in block.lines:\n",
    "            # Draw line bounding polygon\n",
    "            r = line.bounding_polygon\n",
    "            polygon = [(r[0].x, r[0].y), (r[1].x, r[1].y), \n",
    "                      (r[2].x, r[2].y), (r[3].x, r[3].y)]\n",
    "            draw.polygon(polygon, outline=color, width=3)\n",
    "    \n",
    "    # Display annotated image\n",
    "    plt.imshow(image)\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.title('Detected Lines of Text')\n",
    "    plt.show()\n",
    "    print('✓ Line annotation complete')\n",
    "\n",
    "# Annotate lines in the image\n",
    "if result.read is not None:\n",
    "    annotate_lines(image_file, result.read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Annotate Individual Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_words(image_file, detected_text):\n",
    "    \"\"\"\n",
    "    Draw bounding boxes around individual words.\n",
    "    \n",
    "    Args:\n",
    "        image_file: Path to the image file\n",
    "        detected_text: Read result from Azure AI Vision\n",
    "    \"\"\"\n",
    "    print('\\nAnnotating individual words in image...')\n",
    "    \n",
    "    # Prepare image for drawing\n",
    "    image = Image.open(image_file)\n",
    "    fig = plt.figure(figsize=(image.width/100, image.height/100))\n",
    "    plt.axis('off')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    color = 'magenta'\n",
    "    \n",
    "    for block in detected_text.blocks:\n",
    "        for line in block.lines:\n",
    "            for word in line.words:\n",
    "                # Draw word bounding polygon\n",
    "                r = word.bounding_polygon\n",
    "                polygon = [(r[0].x, r[0].y), (r[1].x, r[1].y), \n",
    "                          (r[2].x, r[2].y), (r[3].x, r[3].y)]\n",
    "                draw.polygon(polygon, outline=color, width=2)\n",
    "    \n",
    "    # Display annotated image\n",
    "    plt.imshow(image)\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.title('Detected Words')\n",
    "    plt.show()\n",
    "    print('✓ Word annotation complete')\n",
    "\n",
    "# Annotate words in the image\n",
    "if result.read is not None:\n",
    "    annotate_words(image_file, result.read)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Detailed Text Analysis\n",
    "\n",
    "Let's examine the detected text in more detail, including confidence scores and bounding box coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result.read is not None:\n",
    "    print(\"\\n=== Detailed Text Analysis ===\")\n",
    "    \n",
    "    for block_idx, block in enumerate(result.read.blocks, 1):\n",
    "        print(f\"\\nBlock {block_idx}:\")\n",
    "        \n",
    "        for line_idx, line in enumerate(block.lines, 1):\n",
    "            print(f\"\\n  Line {line_idx}: \\\"{line.text}\\\"\")\n",
    "            \n",
    "            # Show bounding polygon\n",
    "            polygon_points = [(p.x, p.y) for p in line.bounding_polygon]\n",
    "            print(f\"    Bounding polygon: {polygon_points}\")\n",
    "            \n",
    "            # Show individual words\n",
    "            print(f\"    Words ({len(line.words)}):\")\n",
    "            for word in line.words:\n",
    "                print(f\"      • {word.text} (confidence: {word.confidence:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Try Different Images\n",
    "\n",
    "Let's process different types of images with text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available images\n",
    "import glob\n",
    "\n",
    "image_dir = 'python/read-text/images'\n",
    "available_images = glob.glob(f\"{image_dir}/*.jpg\")\n",
    "\n",
    "print(\"Available images for OCR:\")\n",
    "for idx, img_path in enumerate(available_images, 1):\n",
    "    print(f\"{idx}. {os.path.basename(img_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_display_text(image_path):\n",
    "    \"\"\"\n",
    "    Read text from an image and display results.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {os.path.basename(image_path)}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    # Display original image\n",
    "    img = Image.open(image_path)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Original: {os.path.basename(image_path)}')\n",
    "    plt.show()\n",
    "    \n",
    "    # Read text\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        image_data = f.read()\n",
    "    \n",
    "    result = cv_client.analyze(\n",
    "        image_data=image_data,\n",
    "        visual_features=[VisualFeatures.READ]\n",
    "    )\n",
    "    \n",
    "    # Display extracted text\n",
    "    if result.read is not None:\n",
    "        print(\"\\nExtracted Text:\")\n",
    "        print(\"-\" * 60)\n",
    "        for block in result.read.blocks:\n",
    "            for line in block.lines:\n",
    "                print(line.text)\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        # Show annotated image\n",
    "        annotate_lines(image_path, result.read)\n",
    "    else:\n",
    "        print(\"No text detected\")\n",
    "\n",
    "# Uncomment to process additional images\n",
    "# for image_path in available_images:\n",
    "#     read_and_display_text(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Extract Text from a URL\n",
    "\n",
    "You can also analyze images from URLs without downloading them first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Reading text from an image URL\n",
    "# Note: Replace with your own image URL containing text\n",
    "\n",
    "# image_url = \"https://example.com/image-with-text.jpg\"\n",
    "\n",
    "# result = cv_client.analyze_from_url(\n",
    "#     image_url=image_url,\n",
    "#     visual_features=[VisualFeatures.READ]\n",
    "# )\n",
    "\n",
    "# if result.read is not None:\n",
    "#     print(\"Text from URL:\")\n",
    "#     for block in result.read.blocks:\n",
    "#         for line in block.lines:\n",
    "#             print(line.text)\n",
    "\n",
    "print(\"To use URL-based analysis, uncomment the code above and provide a valid image URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you learned how to:\n",
    "- ✓ Use Azure AI Vision's Read API for text extraction\n",
    "- ✓ Process OCR results including blocks, lines, and words\n",
    "- ✓ Visualize detected text with bounding polygons\n",
    "- ✓ Extract detailed information including confidence scores\n",
    "- ✓ Process multiple images programmatically\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "- **Blocks**: Groups of text lines that are logically related\n",
    "- **Lines**: Horizontal sequences of words\n",
    "- **Words**: Individual text elements with bounding polygons\n",
    "- **Bounding Polygon**: Four-point polygon defining the text location\n",
    "- **Confidence Score**: AI model's confidence in the recognized text (0-1)\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try the **Advanced OCR** notebook to explore:\n",
    "  - Handwritten text recognition\n",
    "  - Multi-language text detection\n",
    "  - Document layout analysis\n",
    "  - Text extraction from complex documents\n",
    "- Explore [Azure AI Vision Read API documentation](https://learn.microsoft.com/azure/ai-services/computer-vision/overview-ocr)\n",
    "\n",
    "## Clean Up\n",
    "\n",
    "Remember to manage your Azure resources appropriately to avoid unexpected charges."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
