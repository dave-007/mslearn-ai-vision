{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 02: Advanced Optical Character Recognition (OCR)\n",
    "\n",
    "## Overview\n",
    "This advanced notebook explores sophisticated OCR techniques using Azure AI Vision and Azure Document Intelligence (Form Recognizer). You'll learn to extract text from complex documents, handle multiple languages, process handwritten text, and extract structured data from forms and invoices.\n",
    "\n",
    "## Advanced Topics Covered\n",
    "- Handwritten text recognition\n",
    "- Multi-language text detection and extraction\n",
    "- Document layout analysis and table extraction\n",
    "- Complex document processing (invoices, forms, receipts)\n",
    "- OCR accuracy optimization techniques\n",
    "- Batch document processing\n",
    "- Text post-processing and error correction\n",
    "- Integration with Azure Form Recognizer for structured data\n",
    "- PDF document analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-ai-vision-imageanalysis azure-ai-formrecognizer azure-identity python-dotenv pillow matplotlib pdf2image -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "from dotenv import load_dotenv\n",
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Load configuration\n",
    "load_dotenv('python/.env')\n",
    "vision_endpoint = os.getenv(\"AI_SERVICE_ENDPOINT\")\n",
    "vision_key = os.getenv(\"AI_SERVICE_KEY\")\n",
    "\n",
    "# Initialize Vision client\n",
    "vision_client = ImageAnalysisClient(\n",
    "    endpoint=vision_endpoint,\n",
    "    credential=AzureKeyCredential(vision_key)\n",
    ")\n",
    "\n",
    "# Initialize Document Intelligence client (if available)\n",
    "doc_intel_endpoint = os.getenv(\"DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "doc_intel_key = os.getenv(\"DOCUMENT_INTELLIGENCE_KEY\")\n",
    "\n",
    "if doc_intel_endpoint and doc_intel_key:\n",
    "    doc_client = DocumentAnalysisClient(\n",
    "        endpoint=doc_intel_endpoint,\n",
    "        credential=AzureKeyCredential(doc_intel_key)\n",
    "    )\n",
    "    print(\"\u2713 Document Intelligence client initialized\")\n",
    "else:\n",
    "    doc_client = None\n",
    "    print(\"\u26a0 Document Intelligence credentials not found. Some features will be unavailable.\")\n",
    "\n",
    "print(\"\u2713 Vision client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Handwritten Text Recognition\n",
    "\n",
    "Extract text from handwritten notes, forms, and documents with Azure AI Vision's OCR capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_handwriting(image_path: str, visualize: bool = True) -> Dict:\n",
    "    \"\"\"Recognize handwritten text from an image.\"\"\"\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        image_data = img_file.read()\n",
    "    \n",
    "    # Analyze image for text\n",
    "    result = vision_client.analyze(\n",
    "        image_data=image_data,\n",
    "        visual_features=[VisualFeatures.READ]\n",
    "    )\n",
    "    \n",
    "    extracted_text = []\n",
    "    handwritten_lines = []\n",
    "    \n",
    "    if result.read:\n",
    "        for block in result.read.blocks:\n",
    "            for line in block.lines:\n",
    "                # Note: This is a simplified heuristic approach.\n",
    "                # Lower confidence scores may indicate handwritten text, but Azure Vision API\n",
    "                # doesn't directly expose handwritten vs. printed classification.\n",
    "                # For production use, consider Azure Document Intelligence's handwriting detection.\n",
    "                is_handwritten = any(word.confidence < 0.9 for word in line.words)\n",
    "                \n",
    "                line_info = {\n",
    "                    \"text\": line.text,\n",
    "                    \"confidence\": sum(w.confidence for w in line.words) / len(line.words),\n",
    "                    \"bounding_box\": line.bounding_polygon,\n",
    "                    \"handwritten\": is_handwritten\n",
    "                }\n",
    "                extracted_text.append(line_info)\n",
    "                \n",
    "                if is_handwritten:\n",
    "                    handwritten_lines.append(line.text)\n",
    "    \n",
    "    # Visualize results\n",
    "    if visualize:\n",
    "        img = Image.open(image_path)\n",
    "        fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "        ax.imshow(img)\n",
    "        \n",
    "        for line_info in extracted_text:\n",
    "            polygon = line_info[\"bounding_box\"]\n",
    "            points = [(p.x, p.y) for p in polygon]\n",
    "            points.append(points[0])  # Close polygon\n",
    "            \n",
    "            color = 'red' if line_info[\"handwritten\"] else 'green'\n",
    "            xs, ys = zip(*points)\n",
    "            ax.plot(xs, ys, color=color, linewidth=2)\n",
    "        \n",
    "        ax.set_title(\"Handwritten (Red) vs Printed (Green) Text Detection\")\n",
    "        ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return {\n",
    "        \"all_text\": extracted_text,\n",
    "        \"handwritten_lines\": handwritten_lines,\n",
    "        \"total_lines\": len(extracted_text),\n",
    "        \"handwritten_count\": len(handwritten_lines)\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "print(\"\\n=== Handwritten Text Recognition ===\")\n",
    "print(\"Tip: For best results with handwritten text:\")\n",
    "print(\"  - Ensure good lighting and contrast\")\n",
    "print(\"  - Use high-resolution images\")\n",
    "print(\"  - Avoid blurry or skewed images\")\n",
    "print(\"\\nTest with your own handwritten document images.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi-Language Text Detection\n",
    "\n",
    "Detect and extract text in multiple languages from a single document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_multilingual_text(image_path: str) -> Dict:\n",
    "    \"\"\"Detect text in multiple languages.\"\"\"\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        image_data = img_file.read()\n",
    "    \n",
    "    result = vision_client.analyze(\n",
    "        image_data=image_data,\n",
    "        visual_features=[VisualFeatures.READ]\n",
    "    )\n",
    "    \n",
    "    language_blocks = {}\n",
    "    \n",
    "    if result.read:\n",
    "        for block in result.read.blocks:\n",
    "            for line in block.lines:\n",
    "                # Detect language (simplified - in practice, use language detection library)\n",
    "                text = line.text\n",
    "                \n",
    "                # Basic language detection heuristics\n",
    "                if any('\\u4e00' <= char <= '\\u9fff' for char in text):\n",
    "                    lang = \"Chinese\"\n",
    "                elif any('\\u0600' <= char <= '\\u06ff' for char in text):\n",
    "                    lang = \"Arabic\"\n",
    "                elif any('\\u0400' <= char <= '\\u04ff' for char in text):\n",
    "                    lang = \"Cyrillic\"\n",
    "                elif any('\\u3040' <= char <= '\\u309f' or '\\u30a0' <= char <= '\\u30ff' for char in text):\n",
    "                    lang = \"Japanese\"\n",
    "                elif any('\\uac00' <= char <= '\\ud7af' for char in text):\n",
    "                    lang = \"Korean\"\n",
    "                else:\n",
    "                    lang = \"Latin-based\"\n",
    "                \n",
    "                if lang not in language_blocks:\n",
    "                    language_blocks[lang] = []\n",
    "                language_blocks[lang].append(text)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n=== Multi-Language Detection Results ===\")\n",
    "    for lang, texts in language_blocks.items():\n",
    "        print(f\"\\n{lang} ({len(texts)} lines):\")\n",
    "        for text in texts[:5]:  # Show first 5 lines\n",
    "            print(f\"  {text}\")\n",
    "        if len(texts) > 5:\n",
    "            print(f\"  ... and {len(texts) - 5} more lines\")\n",
    "    \n",
    "    return language_blocks\n",
    "\n",
    "# Example: Create a test image with multiple languages\n",
    "print(\"\\n=== Multi-Language OCR ===\")\n",
    "print(\"Azure AI Vision supports 100+ languages including:\")\n",
    "print(\"  - English, Spanish, French, German, Italian, Portuguese\")\n",
    "print(\"  - Chinese (Simplified & Traditional), Japanese, Korean\")\n",
    "print(\"  - Arabic, Hebrew, Hindi, Thai\")\n",
    "print(\"  - And many more...\")\n",
    "print(\"\\nThe service automatically detects language without requiring specification.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Document Layout Analysis\n",
    "\n",
    "Analyze document structure including paragraphs, headings, tables, and reading order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_document_layout(image_path: str) -> Dict:\n",
    "    \"\"\"Analyze document layout and structure.\"\"\"\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        image_data = img_file.read()\n",
    "    \n",
    "    result = vision_client.analyze(\n",
    "        image_data=image_data,\n",
    "        visual_features=[VisualFeatures.READ]\n",
    "    )\n",
    "    \n",
    "    layout = {\n",
    "        \"blocks\": [],\n",
    "        \"reading_order\": [],\n",
    "        \"columns\": 1\n",
    "    }\n",
    "    \n",
    "    if result.read:\n",
    "        # Analyze blocks\n",
    "        for idx, block in enumerate(result.read.blocks):\n",
    "            block_info = {\n",
    "                \"block_id\": idx,\n",
    "                \"lines\": len(block.lines),\n",
    "                \"text\": \" \".join([line.text for line in block.lines])\n",
    "            }\n",
    "            layout[\"blocks\"].append(block_info)\n",
    "            \n",
    "            # Build reading order\n",
    "            for line in block.lines:\n",
    "                layout[\"reading_order\"].append(line.text)\n",
    "        \n",
    "        # Detect columns (simplified heuristic)\n",
    "        if len(result.read.blocks) > 2:\n",
    "            x_positions = []\n",
    "            for block in result.read.blocks:\n",
    "                if block.lines:\n",
    "                    avg_x = sum(p.x for p in block.lines[0].bounding_polygon) / len(block.lines[0].bounding_polygon)\n",
    "                    x_positions.append(avg_x)\n",
    "            \n",
    "            # If significant gaps in x positions, likely multi-column\n",
    "            x_positions.sort()\n",
    "            gaps = [x_positions[i+1] - x_positions[i] for i in range(len(x_positions)-1)]\n",
    "            if gaps and max(gaps) > 200:  # Threshold for column detection\n",
    "                layout[\"columns\"] = 2\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\n=== Document Layout Analysis ===\")\n",
    "    print(f\"Total blocks: {len(layout['blocks'])}\")\n",
    "    print(f\"Estimated columns: {layout['columns']}\")\n",
    "    print(f\"\\nReading order (first 10 lines):\")\n",
    "    for i, line in enumerate(layout[\"reading_order\"][:10]):\n",
    "        print(f\"  {i+1}. {line}\")\n",
    "    \n",
    "    return layout\n",
    "\n",
    "# Test with sample document\n",
    "print(\"Document layout analysis helps understand:\")\n",
    "print(\"  - Reading order and flow\")\n",
    "print(\"  - Column detection\")\n",
    "print(\"  - Text block grouping\")\n",
    "print(\"  - Document structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Table Extraction with Document Intelligence\n",
    "\n",
    "Extract tables from documents while preserving structure and cell relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tables(document_path: str) -> List[Dict]:\n",
    "    \"\"\"Extract tables from documents using Azure Document Intelligence.\"\"\"\n",
    "    if not doc_client:\n",
    "        print(\"\u26a0 Document Intelligence not configured. Please set credentials in .env file.\")\n",
    "        return []\n",
    "    \n",
    "    with open(document_path, \"rb\") as f:\n",
    "        document = f.read()\n",
    "    \n",
    "    # Use layout model to extract tables\n",
    "    poller = doc_client.begin_analyze_document(\"prebuilt-layout\", document)\n",
    "    result = poller.result()\n",
    "    \n",
    "    tables = []\n",
    "    \n",
    "    for table in result.tables:\n",
    "        # Convert table to structured format\n",
    "        table_data = {\n",
    "            \"row_count\": table.row_count,\n",
    "            \"column_count\": table.column_count,\n",
    "            \"cells\": []\n",
    "        }\n",
    "        \n",
    "        # Create matrix representation\n",
    "        matrix = [[\"\" for _ in range(table.column_count)] for _ in range(table.row_count)]\n",
    "        \n",
    "        for cell in table.cells:\n",
    "            matrix[cell.row_index][cell.column_index] = cell.content\n",
    "            table_data[\"cells\"].append({\n",
    "                \"row\": cell.row_index,\n",
    "                \"column\": cell.column_index,\n",
    "                \"content\": cell.content,\n",
    "                \"is_header\": cell.kind == \"columnHeader\" if hasattr(cell, 'kind') else False\n",
    "            })\n",
    "        \n",
    "        table_data[\"matrix\"] = matrix\n",
    "        tables.append(table_data)\n",
    "    \n",
    "    # Display tables\n",
    "    print(f\"\\n=== Extracted {len(tables)} Table(s) ===\")\n",
    "    for idx, table in enumerate(tables):\n",
    "        print(f\"\\nTable {idx + 1}: {table['row_count']} rows \u00d7 {table['column_count']} columns\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # Display as formatted table\n",
    "        for row in table[\"matrix\"]:\n",
    "            print(\" | \".join(str(cell)[:20].ljust(20) for cell in row))\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    return tables\n",
    "\n",
    "# Example usage\n",
    "print(\"\\n=== Table Extraction ===\")\n",
    "print(\"Document Intelligence can extract tables from:\")\n",
    "print(\"  - PDF documents\")\n",
    "print(\"  - Scanned images\")\n",
    "print(\"  - Complex layouts\")\n",
    "print(\"  - Multi-page documents\")\n",
    "print(\"\\nPreserves: cell structure, headers, and cell spanning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Invoice and Receipt Processing\n",
    "\n",
    "Extract structured data from invoices, receipts, and financial documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_invoice(document_path: str) -> Dict:\n",
    "    \"\"\"Process invoices and extract structured data.\"\"\"\n",
    "    if not doc_client:\n",
    "        print(\"\u26a0 Document Intelligence not configured.\")\n",
    "        return {}\n",
    "    \n",
    "    with open(document_path, \"rb\") as f:\n",
    "        document = f.read()\n",
    "    \n",
    "    # Use prebuilt invoice model\n",
    "    poller = doc_client.begin_analyze_document(\"prebuilt-invoice\", document)\n",
    "    result = poller.result()\n",
    "    \n",
    "    invoice_data = {\n",
    "        \"vendor\": None,\n",
    "        \"customer\": None,\n",
    "        \"invoice_id\": None,\n",
    "        \"invoice_date\": None,\n",
    "        \"due_date\": None,\n",
    "        \"subtotal\": None,\n",
    "        \"tax\": None,\n",
    "        \"total\": None,\n",
    "        \"items\": []\n",
    "    }\n",
    "    \n",
    "    for document in result.documents:\n",
    "        # Extract key fields\n",
    "        fields = document.fields\n",
    "        \n",
    "        if \"VendorName\" in fields:\n",
    "            invoice_data[\"vendor\"] = fields[\"VendorName\"].value\n",
    "        if \"CustomerName\" in fields:\n",
    "            invoice_data[\"customer\"] = fields[\"CustomerName\"].value\n",
    "        if \"InvoiceId\" in fields:\n",
    "            invoice_data[\"invoice_id\"] = fields[\"InvoiceId\"].value\n",
    "        if \"InvoiceDate\" in fields:\n",
    "            invoice_data[\"invoice_date\"] = str(fields[\"InvoiceDate\"].value)\n",
    "        if \"DueDate\" in fields:\n",
    "            invoice_data[\"due_date\"] = str(fields[\"DueDate\"].value)\n",
    "        if \"SubTotal\" in fields:\n",
    "            invoice_data[\"subtotal\"] = fields[\"SubTotal\"].value\n",
    "        if \"TotalTax\" in fields:\n",
    "            invoice_data[\"tax\"] = fields[\"TotalTax\"].value\n",
    "        if \"InvoiceTotal\" in fields:\n",
    "            invoice_data[\"total\"] = fields[\"InvoiceTotal\"].value\n",
    "        \n",
    "        # Extract line items\n",
    "        if \"Items\" in fields:\n",
    "            for item in fields[\"Items\"].value:\n",
    "                item_data = {}\n",
    "                if \"Description\" in item.value:\n",
    "                    item_data[\"description\"] = item.value[\"Description\"].value\n",
    "                if \"Quantity\" in item.value:\n",
    "                    item_data[\"quantity\"] = item.value[\"Quantity\"].value\n",
    "                if \"UnitPrice\" in item.value:\n",
    "                    item_data[\"unit_price\"] = item.value[\"UnitPrice\"].value\n",
    "                if \"Amount\" in item.value:\n",
    "                    item_data[\"amount\"] = item.value[\"Amount\"].value\n",
    "                invoice_data[\"items\"].append(item_data)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n=== Invoice Processing Results ===\")\n",
    "    print(f\"Vendor: {invoice_data['vendor']}\")\n",
    "    print(f\"Customer: {invoice_data['customer']}\")\n",
    "    print(f\"Invoice ID: {invoice_data['invoice_id']}\")\n",
    "    print(f\"Date: {invoice_data['invoice_date']}\")\n",
    "    print(f\"Due Date: {invoice_data['due_date']}\")\n",
    "    print(f\"\\nFinancial Summary:\")\n",
    "    print(f\"  Subtotal: ${invoice_data['subtotal']}\")\n",
    "    print(f\"  Tax: ${invoice_data['tax']}\")\n",
    "    print(f\"  Total: ${invoice_data['total']}\")\n",
    "    print(f\"\\nLine Items ({len(invoice_data['items'])}):\")\n",
    "    for idx, item in enumerate(invoice_data['items'][:5]):\n",
    "        print(f\"  {idx+1}. {item.get('description', 'N/A')} - Qty: {item.get('quantity', 'N/A')} - ${item.get('amount', 'N/A')}\")\n",
    "    \n",
    "    return invoice_data\n",
    "\n",
    "def process_receipt(document_path: str) -> Dict:\n",
    "    \"\"\"Process receipts and extract structured data.\"\"\"\n",
    "    if not doc_client:\n",
    "        print(\"\u26a0 Document Intelligence not configured.\")\n",
    "        return {}\n",
    "    \n",
    "    with open(document_path, \"rb\") as f:\n",
    "        document = f.read()\n",
    "    \n",
    "    # Use prebuilt receipt model\n",
    "    poller = doc_client.begin_analyze_document(\"prebuilt-receipt\", document)\n",
    "    result = poller.result()\n",
    "    \n",
    "    receipt_data = {\n",
    "        \"merchant\": None,\n",
    "        \"transaction_date\": None,\n",
    "        \"transaction_time\": None,\n",
    "        \"items\": [],\n",
    "        \"subtotal\": None,\n",
    "        \"tax\": None,\n",
    "        \"tip\": None,\n",
    "        \"total\": None\n",
    "    }\n",
    "    \n",
    "    for document in result.documents:\n",
    "        fields = document.fields\n",
    "        \n",
    "        if \"MerchantName\" in fields:\n",
    "            receipt_data[\"merchant\"] = fields[\"MerchantName\"].value\n",
    "        if \"TransactionDate\" in fields:\n",
    "            receipt_data[\"transaction_date\"] = str(fields[\"TransactionDate\"].value)\n",
    "        if \"TransactionTime\" in fields:\n",
    "            receipt_data[\"transaction_time\"] = str(fields[\"TransactionTime\"].value)\n",
    "        if \"Subtotal\" in fields:\n",
    "            receipt_data[\"subtotal\"] = fields[\"Subtotal\"].value\n",
    "        if \"Tax\" in fields:\n",
    "            receipt_data[\"tax\"] = fields[\"Tax\"].value\n",
    "        if \"Tip\" in fields:\n",
    "            receipt_data[\"tip\"] = fields[\"Tip\"].value\n",
    "        if \"Total\" in fields:\n",
    "            receipt_data[\"total\"] = fields[\"Total\"].value\n",
    "        \n",
    "        if \"Items\" in fields:\n",
    "            for item in fields[\"Items\"].value:\n",
    "                item_data = {}\n",
    "                if \"Description\" in item.value:\n",
    "                    item_data[\"description\"] = item.value[\"Description\"].value\n",
    "                if \"TotalPrice\" in item.value:\n",
    "                    item_data[\"price\"] = item.value[\"TotalPrice\"].value\n",
    "                receipt_data[\"items\"].append(item_data)\n",
    "    \n",
    "    print(\"\\n=== Receipt Processing Results ===\")\n",
    "    print(f\"Merchant: {receipt_data['merchant']}\")\n",
    "    print(f\"Date: {receipt_data['transaction_date']} {receipt_data['transaction_time']}\")\n",
    "    print(f\"\\nItems:\")\n",
    "    for item in receipt_data['items']:\n",
    "        print(f\"  - {item.get('description', 'N/A')}: ${item.get('price', 'N/A')}\")\n",
    "    print(f\"\\nSubtotal: ${receipt_data['subtotal']}\")\n",
    "    print(f\"Tax: ${receipt_data['tax']}\")\n",
    "    print(f\"Tip: ${receipt_data['tip']}\")\n",
    "    print(f\"Total: ${receipt_data['total']}\")\n",
    "    \n",
    "    return receipt_data\n",
    "\n",
    "# Example\n",
    "print(\"\\n=== Invoice & Receipt Processing ===\")\n",
    "print(\"Supported document types:\")\n",
    "print(\"  - Invoices (prebuilt-invoice)\")\n",
    "print(\"  - Receipts (prebuilt-receipt)\")\n",
    "print(\"  - Business cards (prebuilt-businessCard)\")\n",
    "print(\"  - ID documents (prebuilt-idDocument)\")\n",
    "print(\"  - W-2 forms (prebuilt-tax.us.w2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. OCR Accuracy Optimization\n",
    "\n",
    "Techniques to improve OCR accuracy and quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageEnhance, ImageFilter\n",
    "\n",
    "def preprocess_for_ocr(image_path: str, output_path: str = None) -> str:\n",
    "    \"\"\"Preprocess image to improve OCR accuracy.\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    img = img.convert('L')\n",
    "    \n",
    "    # Increase contrast\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    img = enhancer.enhance(2.0)\n",
    "    \n",
    "    # Increase sharpness\n",
    "    enhancer = ImageEnhance.Sharpness(img)\n",
    "    img = enhancer.enhance(2.0)\n",
    "    \n",
    "    # Apply slight blur to reduce noise\n",
    "    img = img.filter(ImageFilter.MedianFilter(size=3))\n",
    "    \n",
    "    # Increase brightness if needed\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    img = enhancer.enhance(1.2)\n",
    "    \n",
    "    # Save preprocessed image\n",
    "    if output_path is None:\n",
    "        output_path = image_path.replace('.', '_preprocessed.')\n",
    "    img.save(output_path)\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "def compare_ocr_quality(image_path: str) -> Dict:\n",
    "    \"\"\"Compare OCR results before and after preprocessing.\"\"\"\n",
    "    # Process original\n",
    "    print(\"Processing original image...\")\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        result_original = vision_client.analyze(\n",
    "            image_data=f.read(),\n",
    "            visual_features=[VisualFeatures.READ]\n",
    "        )\n",
    "    \n",
    "    # Preprocess and process again\n",
    "    print(\"Preprocessing image...\")\n",
    "    preprocessed_path = preprocess_for_ocr(image_path)\n",
    "    \n",
    "    print(\"Processing preprocessed image...\")\n",
    "    with open(preprocessed_path, \"rb\") as f:\n",
    "        result_preprocessed = vision_client.analyze(\n",
    "            image_data=f.read(),\n",
    "            visual_features=[VisualFeatures.READ]\n",
    "        )\n",
    "    \n",
    "    # Calculate confidence scores\n",
    "    def get_avg_confidence(result):\n",
    "        if not result.read or not result.read.blocks:\n",
    "            return 0.0\n",
    "        total_conf = 0\n",
    "        total_words = 0\n",
    "        for block in result.read.blocks:\n",
    "            for line in block.lines:\n",
    "                for word in line.words:\n",
    "                    total_conf += word.confidence\n",
    "                    total_words += 1\n",
    "        return total_conf / total_words if total_words > 0 else 0.0\n",
    "    \n",
    "    original_conf = get_avg_confidence(result_original)\n",
    "    preprocessed_conf = get_avg_confidence(result_preprocessed)\n",
    "    \n",
    "    print(f\"\\n=== OCR Quality Comparison ===\")\n",
    "    print(f\"Original average confidence: {original_conf:.2%}\")\n",
    "    print(f\"Preprocessed average confidence: {preprocessed_conf:.2%}\")\n",
    "    print(f\"Improvement: {(preprocessed_conf - original_conf):.2%}\")\n",
    "    \n",
    "    return {\n",
    "        \"original_confidence\": original_conf,\n",
    "        \"preprocessed_confidence\": preprocessed_conf,\n",
    "        \"improvement\": preprocessed_conf - original_conf\n",
    "    }\n",
    "\n",
    "# OCR Optimization Tips\n",
    "print(\"\\n=== OCR Accuracy Optimization Tips ===\")\n",
    "print(\"\\n1. Image Quality:\")\n",
    "print(\"   - Use high resolution (300+ DPI for scanned documents)\")\n",
    "print(\"   - Ensure good lighting and contrast\")\n",
    "print(\"   - Avoid blur, glare, and shadows\")\n",
    "print(\"\\n2. Preprocessing:\")\n",
    "print(\"   - Convert to grayscale\")\n",
    "print(\"   - Adjust contrast and brightness\")\n",
    "print(\"   - Deskew rotated images\")\n",
    "print(\"   - Remove noise with filters\")\n",
    "print(\"\\n3. Document Handling:\")\n",
    "print(\"   - Flatten curved pages\")\n",
    "print(\"   - Remove backgrounds\")\n",
    "print(\"   - Crop to text regions\")\n",
    "print(\"\\n4. Post-processing:\")\n",
    "print(\"   - Spell checking\")\n",
    "print(\"   - Dictionary validation\")\n",
    "print(\"   - Context-based correction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batch Document Processing\n",
    "\n",
    "Process multiple documents efficiently with batch operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def process_document_batch(document_paths: List[str], max_workers: int = 5) -> List[Dict]:\n",
    "    \"\"\"Process multiple documents in parallel.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    def process_single(path: str) -> Dict:\n",
    "        \"\"\"Process a single document.\"\"\"\n",
    "        try:\n",
    "            with open(path, \"rb\") as f:\n",
    "                image_data = f.read()\n",
    "            \n",
    "            result = vision_client.analyze(\n",
    "                image_data=image_data,\n",
    "                visual_features=[VisualFeatures.READ]\n",
    "            )\n",
    "            \n",
    "            text_lines = []\n",
    "            if result.read:\n",
    "                for block in result.read.blocks:\n",
    "                    for line in block.lines:\n",
    "                        text_lines.append(line.text)\n",
    "            \n",
    "            return {\n",
    "                \"path\": path,\n",
    "                \"status\": \"success\",\n",
    "                \"text_lines\": text_lines,\n",
    "                \"line_count\": len(text_lines),\n",
    "                \"full_text\": \" \".join(text_lines)\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"path\": path,\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "    \n",
    "    # Process in parallel\n",
    "    print(f\"\\nProcessing {len(document_paths)} documents with {max_workers} workers...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_path = {executor.submit(process_single, path): path for path in document_paths}\n",
    "        \n",
    "        for future in as_completed(future_to_path):\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "            \n",
    "            if result[\"status\"] == \"success\":\n",
    "                print(f\"\u2713 {result['path']}: {result['line_count']} lines extracted\")\n",
    "            else:\n",
    "                print(f\"\u2717 {result['path']}: {result['error']}\")\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\nBatch processing completed in {elapsed:.2f}s\")\n",
    "    print(f\"Average time per document: {elapsed/len(document_paths):.2f}s\")\n",
    "    \n",
    "    # Summary\n",
    "    successful = sum(1 for r in results if r[\"status\"] == \"success\")\n",
    "    print(f\"\\nSuccess rate: {successful}/{len(results)} ({successful/len(results)*100:.1f}%)\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example\n",
    "print(\"\\n=== Batch Document Processing ===\")\n",
    "print(\"Benefits:\")\n",
    "print(\"  - Process multiple documents in parallel\")\n",
    "print(\"  - Reduce total processing time\")\n",
    "print(\"  - Handle errors gracefully\")\n",
    "print(\"  - Track progress and success rates\")\n",
    "print(\"\\nExample usage:\")\n",
    "print('  document_paths = [\"doc1.pdf\", \"doc2.jpg\", \"doc3.png\"]')\n",
    "print('  results = process_document_batch(document_paths, max_workers=5)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Text Post-Processing and Error Correction\n",
    "\n",
    "Clean and correct OCR output using various techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_ocr_text(text: str) -> str:\n",
    "    \"\"\"Clean OCR output text.\"\"\"\n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r' +', ' ', text)\n",
    "    \n",
    "    # Remove multiple newlines\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    \n",
    "    # Fix common OCR errors\n",
    "    replacements = {\n",
    "        'l0': '10',  # lowercase L + zero -> 10\n",
    "        'O0': '00',  # letter O + zero -> 00\n",
    "        'Il': '11',  # capital i + lowercase L -> 11\n",
    "        '|': 'I',    # pipe to capital I\n",
    "        '5': 'S',    # in context of words\n",
    "    }\n",
    "    \n",
    "    for wrong, correct in replacements.items():\n",
    "        text = text.replace(wrong, correct)\n",
    "    \n",
    "    # Remove non-printable characters\n",
    "    text = ''.join(char for char in text if char.isprintable() or char in '\\n\\t')\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "def validate_with_dictionary(words: List[str], min_confidence: float = 0.8) -> List[Dict]:\n",
    "    \"\"\"Validate words against a dictionary.\"\"\"\n",
    "    # This is a simplified version - in production, use a proper spell checker\n",
    "    validated = []\n",
    "    \n",
    "    for word in words:\n",
    "        # Basic validation heuristics\n",
    "        is_valid = True\n",
    "        confidence = 1.0\n",
    "        \n",
    "        # Check for common OCR artifacts\n",
    "        if re.search(r'[|\\\\]', word):  # Contains pipes or backslashes\n",
    "            confidence *= 0.5\n",
    "        \n",
    "        if len(word) > 20:  # Unusually long word\n",
    "            confidence *= 0.7\n",
    "        \n",
    "        if re.search(r'\\d[a-zA-Z]|[a-zA-Z]\\d', word):  # Mixed letters and numbers\n",
    "            confidence *= 0.8\n",
    "        \n",
    "        validated.append({\n",
    "            \"word\": word,\n",
    "            \"valid\": confidence >= min_confidence,\n",
    "            \"confidence\": confidence\n",
    "        })\n",
    "    \n",
    "    return validated\n",
    "\n",
    "def extract_structured_data(text: str) -> Dict:\n",
    "    \"\"\"Extract structured information from OCR text.\"\"\"\n",
    "    extracted = {\n",
    "        \"emails\": [],\n",
    "        \"phone_numbers\": [],\n",
    "        \"dates\": [],\n",
    "        \"urls\": [],\n",
    "        \"currency\": []\n",
    "    }\n",
    "    \n",
    "    # Extract emails\n",
    "    emails = re.findall(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', text)\n",
    "    extracted[\"emails\"] = emails\n",
    "    \n",
    "    # Extract phone numbers (US format)\n",
    "    phones = re.findall(r'\\b\\d{3}[-.]?\\d{3}[-.]?\\d{4}\\b', text)\n",
    "    extracted[\"phone_numbers\"] = phones\n",
    "    \n",
    "    # Extract dates (various formats)\n",
    "    dates = re.findall(r'\\b\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}\\b', text)\n",
    "    extracted[\"dates\"] = dates\n",
    "    \n",
    "    # Extract URLs\n",
    "    urls = re.findall(r'https?://[^\\s]+', text)\n",
    "    extracted[\"urls\"] = urls\n",
    "    \n",
    "    # Extract currency amounts\n",
    "    currency = re.findall(r'\\$\\d+(?:,\\d{3})*(?:\\.\\d{2})?', text)\n",
    "    extracted[\"currency\"] = currency\n",
    "    \n",
    "    return extracted\n",
    "\n",
    "# Example usage\n",
    "sample_text = \"\"\"\n",
    "C0ntact us at: support@example.com or cal| us at 555-123-4567\n",
    "Invoice dat3: 12/31/2023\n",
    "T0tal amount: $1,234.56\n",
    "Visit: https://example.com\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n=== Text Post-Processing ===\")\n",
    "print(\"\\nOriginal (with OCR errors):\")\n",
    "print(sample_text)\n",
    "\n",
    "cleaned = clean_ocr_text(sample_text)\n",
    "print(\"\\nCleaned:\")\n",
    "print(cleaned)\n",
    "\n",
    "structured = extract_structured_data(cleaned)\n",
    "print(\"\\nExtracted Structured Data:\")\n",
    "for key, values in structured.items():\n",
    "    if values:\n",
    "        print(f\"  {key}: {values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Custom Form Processing\n",
    "\n",
    "Train custom models for specific form types using Document Intelligence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_custom_form(document_path: str, model_id: str) -> Dict:\n",
    "    \"\"\"Process documents using a custom trained model.\"\"\"\n",
    "    if not doc_client:\n",
    "        print(\"\u26a0 Document Intelligence not configured.\")\n",
    "        return {}\n",
    "    \n",
    "    with open(document_path, \"rb\") as f:\n",
    "        document = f.read()\n",
    "    \n",
    "    try:\n",
    "        # Use custom model\n",
    "        poller = doc_client.begin_analyze_document(model_id, document)\n",
    "        result = poller.result()\n",
    "        \n",
    "        # Extract fields based on custom model\n",
    "        extracted_fields = {}\n",
    "        \n",
    "        for document in result.documents:\n",
    "            for field_name, field_value in document.fields.items():\n",
    "                extracted_fields[field_name] = {\n",
    "                    \"value\": field_value.value,\n",
    "                    \"confidence\": field_value.confidence\n",
    "                }\n",
    "        \n",
    "        print(f\"\\n=== Custom Form Processing Results ===\")\n",
    "        for field_name, field_data in extracted_fields.items():\n",
    "            print(f\"{field_name}: {field_data['value']} (confidence: {field_data['confidence']:.2%})\")\n",
    "        \n",
    "        return extracted_fields\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing custom form: {str(e)}\")\n",
    "        return {}\n",
    "\n",
    "# Custom model training information\n",
    "print(\"\\n=== Custom Form Processing ===\")\n",
    "print(\"\\nTo train a custom model:\")\n",
    "print(\"1. Collect sample documents (5+ recommended)\")\n",
    "print(\"2. Upload to Azure Storage\")\n",
    "print(\"3. Use Document Intelligence Studio to label fields\")\n",
    "print(\"4. Train the model\")\n",
    "print(\"5. Get model ID and use for processing\")\n",
    "print(\"\\nCustom models are ideal for:\")\n",
    "print(\"  - Company-specific forms\")\n",
    "print(\"  - Unique document layouts\")\n",
    "print(\"  - Industry-specific documents\")\n",
    "print(\"  - Documents with custom fields\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. PDF Document Processing\n",
    "\n",
    "Extract text from multi-page PDF documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_document(pdf_path: str) -> Dict:\n",
    "    \"\"\"Process multi-page PDF documents.\"\"\"\n",
    "    if not doc_client:\n",
    "        print(\"\u26a0 Document Intelligence not configured.\")\n",
    "        return {}\n",
    "    \n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        pdf_data = f.read()\n",
    "    \n",
    "    # Analyze PDF with layout model\n",
    "    poller = doc_client.begin_analyze_document(\"prebuilt-layout\", pdf_data)\n",
    "    result = poller.result()\n",
    "    \n",
    "    pdf_content = {\n",
    "        \"page_count\": len(result.pages),\n",
    "        \"pages\": [],\n",
    "        \"full_text\": \"\",\n",
    "        \"tables\": [],\n",
    "        \"key_value_pairs\": []\n",
    "    }\n",
    "    \n",
    "    # Process each page\n",
    "    for page_num, page in enumerate(result.pages, 1):\n",
    "        page_text = []\n",
    "        \n",
    "        for line in page.lines:\n",
    "            page_text.append(line.content)\n",
    "        \n",
    "        page_content = \"\\n\".join(page_text)\n",
    "        pdf_content[\"pages\"].append({\n",
    "            \"page_number\": page_num,\n",
    "            \"text\": page_content,\n",
    "            \"line_count\": len(page.lines)\n",
    "        })\n",
    "        pdf_content[\"full_text\"] += page_content + \"\\n\\n\"\n",
    "    \n",
    "    # Extract tables\n",
    "    for table in result.tables:\n",
    "        pdf_content[\"tables\"].append({\n",
    "            \"row_count\": table.row_count,\n",
    "            \"column_count\": table.column_count,\n",
    "            \"page\": table.bounding_regions[0].page_number if table.bounding_regions else None\n",
    "        })\n",
    "    \n",
    "    # Extract key-value pairs\n",
    "    if hasattr(result, 'key_value_pairs'):\n",
    "        for kv in result.key_value_pairs:\n",
    "            if kv.key and kv.value:\n",
    "                pdf_content[\"key_value_pairs\"].append({\n",
    "                    \"key\": kv.key.content,\n",
    "                    \"value\": kv.value.content\n",
    "                })\n",
    "    \n",
    "    # Display summary\n",
    "    print(f\"\\n=== PDF Processing Results ===\")\n",
    "    print(f\"Total pages: {pdf_content['page_count']}\")\n",
    "    print(f\"Total tables: {len(pdf_content['tables'])}\")\n",
    "    print(f\"Key-value pairs: {len(pdf_content['key_value_pairs'])}\")\n",
    "    print(f\"\\nPage summaries:\")\n",
    "    for page in pdf_content[\"pages\"]:\n",
    "        print(f\"  Page {page['page_number']}: {page['line_count']} lines\")\n",
    "    \n",
    "    return pdf_content\n",
    "\n",
    "print(\"\\n=== PDF Document Processing ===\")\n",
    "print(\"Capabilities:\")\n",
    "print(\"  - Multi-page text extraction\")\n",
    "print(\"  - Table detection and extraction\")\n",
    "print(\"  - Key-value pair extraction\")\n",
    "print(\"  - Layout preservation\")\n",
    "print(\"  - Reading order detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This advanced OCR notebook covered:\n",
    "\n",
    "1. **Handwritten Text Recognition** - Extract text from handwritten documents\n",
    "2. **Multi-Language Support** - Detect and process text in 100+ languages\n",
    "3. **Document Layout Analysis** - Understand document structure and reading order\n",
    "4. **Table Extraction** - Extract tables while preserving structure\n",
    "5. **Invoice & Receipt Processing** - Extract structured data from financial documents\n",
    "6. **OCR Optimization** - Improve accuracy through preprocessing\n",
    "7. **Batch Processing** - Process multiple documents efficiently\n",
    "8. **Post-Processing** - Clean and correct OCR output\n",
    "9. **Custom Models** - Train models for specific form types\n",
    "10. **PDF Processing** - Extract content from multi-page PDFs\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore Azure Document Intelligence Studio for visual model training\n",
    "- Build automated document processing pipelines\n",
    "- Integrate OCR with downstream applications\n",
    "- Implement quality control and validation workflows\n",
    "- Optimize for production workloads\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Azure AI Vision OCR Documentation](https://learn.microsoft.com/azure/ai-services/computer-vision/overview-ocr)\n",
    "- [Azure Document Intelligence](https://learn.microsoft.com/azure/ai-services/document-intelligence/)\n",
    "- [OCR Best Practices](https://learn.microsoft.com/azure/ai-services/computer-vision/overview-ocr#best-practices)\n",
    "- [Custom Model Training](https://learn.microsoft.com/azure/ai-services/document-intelligence/how-to-guides/build-a-custom-model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}