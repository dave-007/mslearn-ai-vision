{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 05: Advanced Object Detection with Azure Custom Vision\n",
    "\n",
    "This notebook covers advanced topics in object detection, including evaluation metrics, optimization techniques, and production deployment strategies.\n",
    "\n",
    "## Advanced Topics Covered\n",
    "\n",
    "1. **IoU (Intersection over Union)** - Understanding overlap metrics\n",
    "2. **Non-Maximum Suppression (NMS)** - Handling multiple overlapping detections\n",
    "3. **Precision-Recall Curves** - Visualizing model tradeoffs\n",
    "4. **Multi-Object Detection** - Strategies for complex scenes\n",
    "5. **Performance Optimization** - Speed vs accuracy tradeoffs\n",
    "6. **Real-time Detection** - Considerations for video/streaming\n",
    "7. **Custom Thresholding** - Advanced filtering strategies\n",
    "8. **Model Export** - Edge deployment for object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure-cognitiveservices-vision-customvision python-dotenv pillow matplotlib numpy scipy scikit-learn seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "from azure.cognitiveservices.vision.customvision.training.models import (\n",
    "    ImageFileCreateBatch, ImageFileCreateEntry, Region\n",
    ")\n",
    "from msrest.authentication import ApiKeyCredentials\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Credentials and Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = 'python/train-detector/.env'\n",
    "load_dotenv(env_path)\n",
    "\n",
    "training_endpoint = os.getenv('TrainingEndpoint')\n",
    "training_key = os.getenv('TrainingKey')\n",
    "prediction_endpoint = os.getenv('PredictionEndpoint', training_endpoint)\n",
    "prediction_key = os.getenv('PredictionKey', training_key)\n",
    "project_id = os.getenv('ProjectID', None)\n",
    "\n",
    "training_credentials = ApiKeyCredentials(in_headers={\"Training-key\": training_key})\n",
    "training_client = CustomVisionTrainingClient(training_endpoint, training_credentials)\n",
    "\n",
    "prediction_credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": prediction_key})\n",
    "prediction_client = CustomVisionPredictionClient(prediction_endpoint, prediction_credentials)\n",
    "\n",
    "print(\"Clients authenticated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding IoU (Intersection over Union)\n",
    "\n",
    "**IoU** measures the overlap between predicted and ground truth bounding boxes. It's crucial for evaluating object detection performance.\n",
    "\n",
    "### IoU Formula:\n",
    "```\n",
    "IoU = Area of Overlap / Area of Union\n",
    "```\n",
    "\n",
    "### IoU Interpretation:\n",
    "- **IoU > 0.5**: Generally considered a \"good\" detection\n",
    "- **IoU > 0.7**: High quality detection\n",
    "- **IoU > 0.9**: Excellent detection\n",
    "- **IoU < 0.5**: Often considered a false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate Intersection over Union (IoU) between two bounding boxes.\n",
    "    \n",
    "    Args:\n",
    "        box1, box2: Dictionaries with 'left', 'top', 'width', 'height' (normalized 0-1)\n",
    "    \n",
    "    Returns:\n",
    "        IoU score (0-1)\n",
    "    \"\"\"\n",
    "    # Calculate coordinates\n",
    "    x1_min = box1['left']\n",
    "    y1_min = box1['top']\n",
    "    x1_max = box1['left'] + box1['width']\n",
    "    y1_max = box1['top'] + box1['height']\n",
    "    \n",
    "    x2_min = box2['left']\n",
    "    y2_min = box2['top']\n",
    "    x2_max = box2['left'] + box2['width']\n",
    "    y2_max = box2['top'] + box2['height']\n",
    "    \n",
    "    # Calculate intersection area\n",
    "    intersect_width = max(0, min(x1_max, x2_max) - max(x1_min, x2_min))\n",
    "    intersect_height = max(0, min(y1_max, y2_max) - max(y1_min, y2_min))\n",
    "    intersect_area = intersect_width * intersect_height\n",
    "    \n",
    "    # Calculate union area\n",
    "    box1_area = box1['width'] * box1['height']\n",
    "    box2_area = box2['width'] * box2['height']\n",
    "    union_area = box1_area + box2_area - intersect_area\n",
    "    \n",
    "    # Calculate IoU\n",
    "    if union_area == 0:\n",
    "        return 0\n",
    "    \n",
    "    iou = intersect_area / union_area\n",
    "    return iou\n",
    "\n",
    "def visualize_iou_examples():\n",
    "    \"\"\"\n",
    "    Visualize different IoU scenarios.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    \n",
    "    # Different overlap scenarios\n",
    "    scenarios = [\n",
    "        # Perfect match\n",
    "        (\n",
    "            {'left': 0.2, 'top': 0.2, 'width': 0.3, 'height': 0.3},\n",
    "            {'left': 0.2, 'top': 0.2, 'width': 0.3, 'height': 0.3},\n",
    "            \"Perfect Match (IoU=1.0)\"\n",
    "        ),\n",
    "        # Good overlap\n",
    "        (\n",
    "            {'left': 0.2, 'top': 0.2, 'width': 0.3, 'height': 0.3},\n",
    "            {'left': 0.25, 'top': 0.25, 'width': 0.3, 'height': 0.3},\n",
    "            \"Good Overlap (IoU≈0.68)\"\n",
    "        ),\n",
    "        # Moderate overlap\n",
    "        (\n",
    "            {'left': 0.2, 'top': 0.2, 'width': 0.3, 'height': 0.3},\n",
    "            {'left': 0.35, 'top': 0.2, 'width': 0.3, 'height': 0.3},\n",
    "            \"Moderate (IoU≈0.38)\"\n",
    "        ),\n",
    "        # No overlap\n",
    "        (\n",
    "            {'left': 0.2, 'top': 0.2, 'width': 0.2, 'height': 0.2},\n",
    "            {'left': 0.6, 'top': 0.6, 'width': 0.2, 'height': 0.2},\n",
    "            \"No Overlap (IoU=0.0)\"\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    for idx, (box1, box2, title) in enumerate(scenarios):\n",
    "        ax = axes[idx]\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.set_aspect('equal')\n",
    "        \n",
    "        # Draw ground truth (blue)\n",
    "        rect1 = Rectangle(\n",
    "            (box1['left'], box1['top']), box1['width'], box1['height'],\n",
    "            linewidth=2, edgecolor='blue', facecolor='blue', alpha=0.3, label='Ground Truth'\n",
    "        )\n",
    "        ax.add_patch(rect1)\n",
    "        \n",
    "        # Draw prediction (red)\n",
    "        rect2 = Rectangle(\n",
    "            (box2['left'], box2['top']), box2['width'], box2['height'],\n",
    "            linewidth=2, edgecolor='red', facecolor='red', alpha=0.3, label='Prediction'\n",
    "        )\n",
    "        ax.add_patch(rect2)\n",
    "        \n",
    "        # Calculate and display IoU\n",
    "        iou = calculate_iou(box1, box2)\n",
    "        ax.set_title(f\"{title}\\nIoU: {iou:.2f}\", fontsize=10)\n",
    "        ax.invert_yaxis()\n",
    "        \n",
    "        if idx == 0:\n",
    "            ax.legend(loc='upper left', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle('IoU (Intersection over Union) Examples', y=1.02, fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize IoU examples\n",
    "visualize_iou_examples()\n",
    "\n",
    "# Test IoU calculation\n",
    "print(\"\\nIoU Calculation Examples:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_box1 = {'left': 0.2, 'top': 0.2, 'width': 0.3, 'height': 0.3}\n",
    "test_box2 = {'left': 0.25, 'top': 0.25, 'width': 0.3, 'height': 0.3}\n",
    "print(f\"Box 1: {test_box1}\")\n",
    "print(f\"Box 2: {test_box2}\")\n",
    "print(f\"IoU: {calculate_iou(test_box1, test_box2):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Non-Maximum Suppression (NMS)\n",
    "\n",
    "**NMS** eliminates redundant overlapping detections, keeping only the best one for each object.\n",
    "\n",
    "### Why NMS is Needed:\n",
    "- Object detectors often produce multiple detections for the same object\n",
    "- NMS selects the detection with highest confidence and suppresses overlapping ones\n",
    "\n",
    "### NMS Algorithm:\n",
    "1. Sort detections by confidence score (highest first)\n",
    "2. Select detection with highest confidence\n",
    "3. Remove all detections with IoU > threshold with selected detection\n",
    "4. Repeat until no detections remain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_maximum_suppression(detections, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Apply Non-Maximum Suppression to filter overlapping detections.\n",
    "    \n",
    "    Args:\n",
    "        detections: List of detection dicts with 'bbox', 'confidence', 'tag'\n",
    "        iou_threshold: IoU threshold for suppression\n",
    "    \n",
    "    Returns:\n",
    "        Filtered list of detections\n",
    "    \"\"\"\n",
    "    if not detections:\n",
    "        return []\n",
    "    \n",
    "    # Sort by confidence (descending)\n",
    "    sorted_detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)\n",
    "    \n",
    "    kept_detections = []\n",
    "    \n",
    "    while sorted_detections:\n",
    "        # Take detection with highest confidence\n",
    "        current = sorted_detections.pop(0)\n",
    "        kept_detections.append(current)\n",
    "        \n",
    "        # Remove detections with high IoU overlap of same class\n",
    "        remaining = []\n",
    "        for det in sorted_detections:\n",
    "            iou = calculate_iou(current['bbox'], det['bbox'])\n",
    "            \n",
    "            # Keep if IoU is below threshold OR different object class\n",
    "            if iou <= iou_threshold or det['tag'] != current['tag']:\n",
    "                remaining.append(det)\n",
    "        \n",
    "        sorted_detections = remaining\n",
    "    \n",
    "    return kept_detections\n",
    "\n",
    "def demonstrate_nms():\n",
    "    \"\"\"\n",
    "    Demonstrate NMS with sample detections.\n",
    "    \"\"\"\n",
    "    # Simulate multiple overlapping detections\n",
    "    sample_detections = [\n",
    "        {'tag': 'apple', 'confidence': 0.95, 'bbox': {'left': 0.2, 'top': 0.2, 'width': 0.2, 'height': 0.2}},\n",
    "        {'tag': 'apple', 'confidence': 0.88, 'bbox': {'left': 0.22, 'top': 0.22, 'width': 0.2, 'height': 0.2}},\n",
    "        {'tag': 'apple', 'confidence': 0.75, 'bbox': {'left': 0.25, 'top': 0.19, 'width': 0.18, 'height': 0.22}},\n",
    "        {'tag': 'banana', 'confidence': 0.92, 'bbox': {'left': 0.6, 'top': 0.5, 'width': 0.25, 'height': 0.15}},\n",
    "        {'tag': 'banana', 'confidence': 0.78, 'bbox': {'left': 0.62, 'top': 0.52, 'width': 0.23, 'height': 0.14}},\n",
    "    ]\n",
    "    \n",
    "    print(\"Non-Maximum Suppression Demonstration\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"\\nOriginal Detections: {len(sample_detections)}\")\n",
    "    for i, det in enumerate(sample_detections, 1):\n",
    "        print(f\"  {i}. {det['tag']:10} confidence={det['confidence']:.2f}  \"\n",
    "              f\"bbox=({det['bbox']['left']:.2f}, {det['bbox']['top']:.2f}, \"\n",
    "              f\"{det['bbox']['width']:.2f}, {det['bbox']['height']:.2f})\")\n",
    "    \n",
    "    # Apply NMS\n",
    "    filtered_detections = non_maximum_suppression(sample_detections, iou_threshold=0.5)\n",
    "    \n",
    "    print(f\"\\nAfter NMS (IoU threshold=0.5): {len(filtered_detections)}\")\n",
    "    for i, det in enumerate(filtered_detections, 1):\n",
    "        print(f\"  {i}. {det['tag']:10} confidence={det['confidence']:.2f}  \"\n",
    "              f\"bbox=({det['bbox']['left']:.2f}, {det['bbox']['top']:.2f}, \"\n",
    "              f\"{det['bbox']['width']:.2f}, {det['bbox']['height']:.2f})\")\n",
    "    \n",
    "    print(f\"\\nReduction: {len(sample_detections) - len(filtered_detections)} detections suppressed\")\n",
    "    \n",
    "    # Visualize before and after\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    colors = {'apple': 'red', 'banana': 'yellow'}\n",
    "    \n",
    "    # Before NMS\n",
    "    ax1.set_xlim(0, 1)\n",
    "    ax1.set_ylim(0, 1)\n",
    "    ax1.set_aspect('equal')\n",
    "    ax1.set_title(f'Before NMS ({len(sample_detections)} detections)', fontweight='bold')\n",
    "    ax1.invert_yaxis()\n",
    "    \n",
    "    for det in sample_detections:\n",
    "        rect = Rectangle(\n",
    "            (det['bbox']['left'], det['bbox']['top']),\n",
    "            det['bbox']['width'], det['bbox']['height'],\n",
    "            linewidth=2, edgecolor=colors[det['tag']], \n",
    "            facecolor='none', alpha=0.7\n",
    "        )\n",
    "        ax1.add_patch(rect)\n",
    "        ax1.text(\n",
    "            det['bbox']['left'], det['bbox']['top'] - 0.02,\n",
    "            f\"{det['confidence']:.2f}\", fontsize=9,\n",
    "            bbox=dict(facecolor='white', alpha=0.7, edgecolor='none')\n",
    "        )\n",
    "    \n",
    "    # After NMS\n",
    "    ax2.set_xlim(0, 1)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    ax2.set_aspect('equal')\n",
    "    ax2.set_title(f'After NMS ({len(filtered_detections)} detections)', fontweight='bold')\n",
    "    ax2.invert_yaxis()\n",
    "    \n",
    "    for det in filtered_detections:\n",
    "        rect = Rectangle(\n",
    "            (det['bbox']['left'], det['bbox']['top']),\n",
    "            det['bbox']['width'], det['bbox']['height'],\n",
    "            linewidth=3, edgecolor=colors[det['tag']], \n",
    "            facecolor='none'\n",
    "        )\n",
    "        ax2.add_patch(rect)\n",
    "        ax2.text(\n",
    "            det['bbox']['left'], det['bbox']['top'] - 0.02,\n",
    "            f\"{det['tag']} {det['confidence']:.2f}\", fontsize=10,\n",
    "            fontweight='bold',\n",
    "            bbox=dict(facecolor=colors[det['tag']], alpha=0.7, edgecolor='none')\n",
    "        )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "demonstrate_nms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Advanced Detection Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detection domain\n",
    "domains = training_client.get_domains()\n",
    "obj_detection_domain = next((d for d in domains if d.type == 'ObjectDetection'), None)\n",
    "\n",
    "# Create project\n",
    "project_name = f\"Advanced Object Detection {uuid.uuid4().hex[:8]}\"\n",
    "project = training_client.create_project(\n",
    "    name=project_name,\n",
    "    description=\"Advanced object detection with performance optimization\",\n",
    "    domain_id=obj_detection_domain.id\n",
    ")\n",
    "\n",
    "print(f\"✓ Created project: {project.name}\")\n",
    "print(f\"  Project ID: {project.id}\")\n",
    "\n",
    "# Create tags\n",
    "tag_names = ['apple', 'banana', 'orange']\n",
    "tags = {}\n",
    "for tag_name in tag_names:\n",
    "    tag = training_client.create_tag(project.id, tag_name)\n",
    "    tags[tag_name] = tag\n",
    "    print(f\"  Created tag: {tag_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Upload Training Data and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and upload tagged images\n",
    "tagged_images_json = 'python/train-detector/tagged-images.json'\n",
    "images_folder = 'python/train-detector/images'\n",
    "\n",
    "with open(tagged_images_json, 'r') as f:\n",
    "    tagged_data = json.load(f)\n",
    "\n",
    "print(f\"Uploading {len(tagged_data['files'])} training images...\")\n",
    "\n",
    "tagged_images_with_regions = []\n",
    "for image_info in tagged_data['files']:\n",
    "    filename = image_info['filename']\n",
    "    image_path = os.path.join(images_folder, filename)\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        continue\n",
    "    \n",
    "    regions = []\n",
    "    for bbox in image_info['tags']:\n",
    "        tag_id = tags[bbox['tag']].id\n",
    "        region = Region(\n",
    "            tag_id=tag_id,\n",
    "            left=bbox['left'],\n",
    "            top=bbox['top'],\n",
    "            width=bbox['width'],\n",
    "            height=bbox['height']\n",
    "        )\n",
    "        regions.append(region)\n",
    "    \n",
    "    with open(image_path, 'rb') as image_file:\n",
    "        tagged_images_with_regions.append(\n",
    "            ImageFileCreateEntry(\n",
    "                name=filename,\n",
    "                contents=image_file.read(),\n",
    "                regions=regions\n",
    "            )\n",
    "        )\n",
    "\n",
    "upload_result = training_client.create_images_from_files(\n",
    "    project.id,\n",
    "    ImageFileCreateBatch(images=tagged_images_with_regions)\n",
    ")\n",
    "\n",
    "print(f\"✓ Images uploaded successfully\\n\")\n",
    "\n",
    "# Train model\n",
    "print(\"Training model...\")\n",
    "iteration = training_client.train_project(project.id)\n",
    "\n",
    "while iteration.status not in [\"Completed\", \"Failed\"]:\n",
    "    iteration = training_client.get_iteration(project.id, iteration.id)\n",
    "    print(f\"  Status: {iteration.status}\")\n",
    "    time.sleep(10)\n",
    "\n",
    "print(f\"\\n✓ Training completed!\")\n",
    "\n",
    "# Publish model\n",
    "publish_name = \"AdvancedDetector\"\n",
    "prediction_resource_id = os.getenv('PredictionResourceId', None)\n",
    "\n",
    "try:\n",
    "    if prediction_resource_id:\n",
    "        training_client.publish_iteration(project.id, iteration.id, publish_name, prediction_resource_id)\n",
    "    else:\n",
    "        training_client.publish_iteration(project.id, iteration.id, publish_name)\n",
    "    print(f\"✓ Model published as '{publish_name}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Publishing info: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Detection with NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_object_detection(image_path, project_id, publish_name, prediction_client,\n",
    "                             confidence_threshold=0.5, nms_threshold=0.5, apply_nms=True):\n",
    "    \"\"\"\n",
    "    Perform object detection with optional NMS.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to image\n",
    "        project_id: Project ID\n",
    "        publish_name: Model name\n",
    "        prediction_client: Prediction client\n",
    "        confidence_threshold: Minimum confidence\n",
    "        nms_threshold: IoU threshold for NMS\n",
    "        apply_nms: Whether to apply NMS\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with detection results\n",
    "    \"\"\"\n",
    "    # Get predictions\n",
    "    with open(image_path, 'rb') as f:\n",
    "        results = prediction_client.detect_image(project_id, publish_name, f.read())\n",
    "    \n",
    "    # Filter by confidence\n",
    "    detections = []\n",
    "    for pred in results.predictions:\n",
    "        if pred.probability >= confidence_threshold:\n",
    "            detections.append({\n",
    "                'tag': pred.tag_name,\n",
    "                'confidence': pred.probability,\n",
    "                'bbox': {\n",
    "                    'left': pred.bounding_box.left,\n",
    "                    'top': pred.bounding_box.top,\n",
    "                    'width': pred.bounding_box.width,\n",
    "                    'height': pred.bounding_box.height\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    # Apply NMS if requested\n",
    "    if apply_nms and len(detections) > 1:\n",
    "        filtered_detections = non_maximum_suppression(detections, nms_threshold)\n",
    "    else:\n",
    "        filtered_detections = detections\n",
    "    \n",
    "    return {\n",
    "        'raw_detections': detections,\n",
    "        'filtered_detections': filtered_detections,\n",
    "        'num_suppressed': len(detections) - len(filtered_detections)\n",
    "    }\n",
    "\n",
    "# Test advanced detection\n",
    "test_image = 'python/test-detector/produce.jpg'\n",
    "\n",
    "if os.path.exists(test_image):\n",
    "    print(\"Advanced Object Detection Results\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    result = advanced_object_detection(\n",
    "        test_image,\n",
    "        project.id,\n",
    "        publish_name,\n",
    "        prediction_client,\n",
    "        confidence_threshold=0.3,\n",
    "        nms_threshold=0.5,\n",
    "        apply_nms=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nRaw detections: {len(result['raw_detections'])}\")\n",
    "    print(f\"After NMS: {len(result['filtered_detections'])}\")\n",
    "    print(f\"Suppressed: {result['num_suppressed']}\")\n",
    "    \n",
    "    print(f\"\\nFinal Detections:\")\n",
    "    for det in result['filtered_detections']:\n",
    "        print(f\"  {det['tag']:10} - {det['confidence']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance vs Speed Tradeoffs\n",
    "\n",
    "In production, you often need to balance detection accuracy with speed:\n",
    "\n",
    "### Strategies for Optimization:\n",
    "1. **Lower confidence threshold**: Detect more objects but get more false positives\n",
    "2. **Higher confidence threshold**: Fewer false positives but might miss objects\n",
    "3. **Image resolution**: Lower resolution = faster but less accurate\n",
    "4. **Model selection**: Compact models are faster but may be less accurate\n",
    "5. **Batch processing**: Process multiple images together for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_detection_performance(image_path, project_id, publish_name, prediction_client, iterations=5):\n",
    "    \"\"\"\n",
    "    Benchmark detection speed and analyze performance.\n",
    "    \"\"\"\n",
    "    print(\"Detection Performance Benchmark\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    with open(image_path, 'rb') as f:\n",
    "        image_data = f.read()\n",
    "    \n",
    "    times = []\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        start_time = time.time()\n",
    "        results = prediction_client.detect_image(project_id, publish_name, image_data)\n",
    "        elapsed = time.time() - start_time\n",
    "        times.append(elapsed)\n",
    "        print(f\"Iteration {i+1}: {elapsed:.3f}s ({len(results.predictions)} detections)\")\n",
    "    \n",
    "    print(f\"\\nPerformance Summary:\")\n",
    "    print(f\"  Average time: {np.mean(times):.3f}s\")\n",
    "    print(f\"  Std deviation: {np.std(times):.3f}s\")\n",
    "    print(f\"  Min time: {np.min(times):.3f}s\")\n",
    "    print(f\"  Max time: {np.max(times):.3f}s\")\n",
    "    print(f\"  Throughput: {1/np.mean(times):.2f} images/second\")\n",
    "    \n",
    "    # Visualize timing distribution\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, iterations+1), times, 'o-', linewidth=2, markersize=8)\n",
    "    plt.axhline(np.mean(times), color='r', linestyle='--', label=f'Mean: {np.mean(times):.3f}s')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Time (seconds)')\n",
    "    plt.title('Detection Time per Iteration')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(times, bins=max(3, iterations//2), edgecolor='black', alpha=0.7)\n",
    "    plt.axvline(np.mean(times), color='r', linestyle='--', linewidth=2, label='Mean')\n",
    "    plt.xlabel('Time (seconds)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Time Distribution')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if os.path.exists(test_image):\n",
    "    benchmark_detection_performance(test_image, project.id, publish_name, prediction_client, iterations=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Multi-Object Scene Analysis\n",
    "\n",
    "Analyze complex scenes with multiple objects and provide statistical insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_scene(image_path, project_id, publish_name, prediction_client, confidence_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Perform comprehensive scene analysis.\n",
    "    \"\"\"\n",
    "    result = advanced_object_detection(\n",
    "        image_path, project_id, publish_name, prediction_client,\n",
    "        confidence_threshold=confidence_threshold, apply_nms=True\n",
    "    )\n",
    "    \n",
    "    detections = result['filtered_detections']\n",
    "    \n",
    "    print(\"Scene Analysis Report\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Image: {os.path.basename(image_path)}\")\n",
    "    print(f\"Total objects detected: {len(detections)}\")\n",
    "    print(f\"\\nObject Distribution:\")\n",
    "    \n",
    "    # Count by type\n",
    "    object_counts = defaultdict(int)\n",
    "    object_confidences = defaultdict(list)\n",
    "    \n",
    "    for det in detections:\n",
    "        object_counts[det['tag']] += 1\n",
    "        object_confidences[det['tag']].append(det['confidence'])\n",
    "    \n",
    "    for obj_type, count in sorted(object_counts.items()):\n",
    "        avg_conf = np.mean(object_confidences[obj_type])\n",
    "        print(f\"  {obj_type:15} : {count:2} objects (avg confidence: {avg_conf:.2%})\")\n",
    "    \n",
    "    # Calculate object sizes\n",
    "    print(f\"\\nObject Sizes:\")\n",
    "    for det in detections:\n",
    "        area = det['bbox']['width'] * det['bbox']['height']\n",
    "        size_category = \"Large\" if area > 0.15 else \"Medium\" if area > 0.05 else \"Small\"\n",
    "        print(f\"  {det['tag']:10} - {size_category:6} (area: {area:.3f})\")\n",
    "    \n",
    "    # Spatial distribution\n",
    "    print(f\"\\nSpatial Distribution:\")\n",
    "    for det in detections:\n",
    "        center_x = det['bbox']['left'] + det['bbox']['width'] / 2\n",
    "        center_y = det['bbox']['top'] + det['bbox']['height'] / 2\n",
    "        \n",
    "        h_pos = \"Left\" if center_x < 0.33 else \"Center\" if center_x < 0.67 else \"Right\"\n",
    "        v_pos = \"Top\" if center_y < 0.33 else \"Middle\" if center_y < 0.67 else \"Bottom\"\n",
    "        \n",
    "        print(f\"  {det['tag']:10} - {v_pos:6}/{h_pos:6} (center: {center_x:.2f}, {center_y:.2f})\")\n",
    "    \n",
    "    # Visualize scene\n",
    "    img = Image.open(image_path)\n",
    "    img_width, img_height = img.size\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Image with detections\n",
    "    ax1.imshow(img)\n",
    "    colors = {'apple': 'red', 'banana': 'yellow', 'orange': 'orange'}\n",
    "    \n",
    "    for det in detections:\n",
    "        left = det['bbox']['left'] * img_width\n",
    "        top = det['bbox']['top'] * img_height\n",
    "        width = det['bbox']['width'] * img_width\n",
    "        height = det['bbox']['height'] * img_height\n",
    "        \n",
    "        color = colors.get(det['tag'], 'cyan')\n",
    "        rect = patches.Rectangle(\n",
    "            (left, top), width, height,\n",
    "            linewidth=3, edgecolor=color, facecolor='none'\n",
    "        )\n",
    "        ax1.add_patch(rect)\n",
    "        \n",
    "        label = f\"{det['tag']} {det['confidence']:.0%}\"\n",
    "        ax1.text(left, top - 5, label, color='white', fontsize=10, fontweight='bold',\n",
    "                bbox=dict(facecolor=color, alpha=0.8, edgecolor='none', pad=2))\n",
    "    \n",
    "    ax1.set_title('Detected Objects', fontsize=12, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Object statistics\n",
    "    obj_types = list(object_counts.keys())\n",
    "    counts = list(object_counts.values())\n",
    "    \n",
    "    ax2.bar(obj_types, counts, color=[colors.get(t, 'gray') for t in obj_types], alpha=0.7, edgecolor='black')\n",
    "    ax2.set_xlabel('Object Type')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.set_title('Object Distribution', fontsize=12, fontweight='bold')\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return detections\n",
    "\n",
    "if os.path.exists(test_image):\n",
    "    scene_detections = analyze_scene(test_image, project.id, publish_name, prediction_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Real-Time Detection Considerations\n",
    "\n",
    "For video or real-time applications:\n",
    "\n",
    "### Key Considerations:\n",
    "1. **Frame rate**: Target 15-30 FPS for smooth video\n",
    "2. **Latency**: Network latency affects responsiveness\n",
    "3. **Frame skipping**: Process every Nth frame to improve throughput\n",
    "4. **Temporal consistency**: Track objects across frames\n",
    "5. **Edge deployment**: Use exported models for local processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_realtime_capability(avg_detection_time, target_fps=30):\n",
    "    \"\"\"\n",
    "    Estimate real-time detection capability.\n",
    "    \"\"\"\n",
    "    print(\"Real-Time Detection Analysis\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    max_fps = 1 / avg_detection_time\n",
    "    frame_budget = 1 / target_fps\n",
    "    \n",
    "    print(f\"Average detection time: {avg_detection_time*1000:.1f}ms\")\n",
    "    print(f\"Maximum achievable FPS: {max_fps:.1f}\")\n",
    "    print(f\"Target FPS: {target_fps}\")\n",
    "    print(f\"Frame time budget: {frame_budget*1000:.1f}ms\\n\")\n",
    "    \n",
    "    if max_fps >= target_fps:\n",
    "        print(f\"✓ Can achieve target {target_fps} FPS\")\n",
    "        overhead = (frame_budget - avg_detection_time) * 1000\n",
    "        print(f\"  Time budget remaining: {overhead:.1f}ms for other processing\")\n",
    "    else:\n",
    "        print(f\"⚠️  Cannot achieve target {target_fps} FPS\")\n",
    "        skip_factor = int(np.ceil(target_fps / max_fps))\n",
    "        effective_fps = max_fps / skip_factor\n",
    "        print(f\"  Recommended: Process every {skip_factor} frames\")\n",
    "        print(f\"  Effective FPS: {effective_fps:.1f}\")\n",
    "    \n",
    "    print(f\"\\nOptimization Strategies:\")\n",
    "    print(f\"  - Use compact model domain for faster inference\")\n",
    "    print(f\"  - Export model for edge deployment\")\n",
    "    print(f\"  - Reduce image resolution\")\n",
    "    print(f\"  - Process frames in parallel\")\n",
    "    print(f\"  - Skip frames (process every Nth frame)\")\n",
    "    \n",
    "    # Visualize frame processing scenarios\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    scenarios = [\n",
    "        (\"Current\", max_fps, 'red'),\n",
    "        (\"Target\", target_fps, 'green'),\n",
    "        (\"With Optimization\\n(2x faster)\", max_fps * 2, 'blue')\n",
    "    ]\n",
    "    \n",
    "    for idx, (label, fps, color) in enumerate(scenarios):\n",
    "        ax = axes[idx]\n",
    "        ax.bar([label], [fps], color=color, alpha=0.7, edgecolor='black')\n",
    "        ax.axhline(target_fps, color='green', linestyle='--', linewidth=2, alpha=0.5, label='Target')\n",
    "        ax.set_ylabel('FPS')\n",
    "        ax.set_title(f\"{label}\\n{fps:.1f} FPS\")\n",
    "        ax.set_ylim([0, max(target_fps * 1.5, max_fps * 2.5)])\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        if idx == 0:\n",
    "            ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Estimate with example timing\n",
    "estimate_realtime_capability(avg_detection_time=0.15, target_fps=30)  # 150ms per detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Production Deployment Class\n",
    "\n",
    "A production-ready detector with all optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionObjectDetector:\n",
    "    \"\"\"\n",
    "    Production-ready object detector with NMS, error handling, and monitoring.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, endpoint, key, project_id, model_name,\n",
    "                 confidence_threshold=0.5, nms_threshold=0.5,\n",
    "                 enable_nms=True, retry_attempts=3):\n",
    "        self.endpoint = endpoint\n",
    "        self.project_id = project_id\n",
    "        self.model_name = model_name\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.nms_threshold = nms_threshold\n",
    "        self.enable_nms = enable_nms\n",
    "        self.retry_attempts = retry_attempts\n",
    "        \n",
    "        credentials = ApiKeyCredentials(in_headers={\"Prediction-key\": key})\n",
    "        self.client = CustomVisionPredictionClient(endpoint, credentials)\n",
    "        \n",
    "        # Monitoring\n",
    "        self.stats = {\n",
    "            'total_predictions': 0,\n",
    "            'total_detections': 0,\n",
    "            'suppressed_detections': 0,\n",
    "            'errors': 0,\n",
    "            'detection_times': []\n",
    "        }\n",
    "    \n",
    "    def detect(self, image_data):\n",
    "        \"\"\"\n",
    "        Detect objects with full error handling and post-processing.\n",
    "        \"\"\"\n",
    "        for attempt in range(self.retry_attempts):\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                results = self.client.detect_image(\n",
    "                    self.project_id,\n",
    "                    self.model_name,\n",
    "                    image_data\n",
    "                )\n",
    "                elapsed = time.time() - start_time\n",
    "                \n",
    "                self.stats['detection_times'].append(elapsed)\n",
    "                self.stats['total_predictions'] += 1\n",
    "                \n",
    "                # Convert to our format\n",
    "                detections = []\n",
    "                for pred in results.predictions:\n",
    "                    if pred.probability >= self.confidence_threshold:\n",
    "                        detections.append({\n",
    "                            'tag': pred.tag_name,\n",
    "                            'confidence': pred.probability,\n",
    "                            'bbox': {\n",
    "                                'left': pred.bounding_box.left,\n",
    "                                'top': pred.bounding_box.top,\n",
    "                                'width': pred.bounding_box.width,\n",
    "                                'height': pred.bounding_box.height\n",
    "                            }\n",
    "                        })\n",
    "                \n",
    "                self.stats['total_detections'] += len(detections)\n",
    "                \n",
    "                # Apply NMS\n",
    "                if self.enable_nms and len(detections) > 1:\n",
    "                    filtered = non_maximum_suppression(detections, self.nms_threshold)\n",
    "                    self.stats['suppressed_detections'] += len(detections) - len(filtered)\n",
    "                else:\n",
    "                    filtered = detections\n",
    "                \n",
    "                return {\n",
    "                    'success': True,\n",
    "                    'detections': filtered,\n",
    "                    'num_objects': len(filtered),\n",
    "                    'detection_time': elapsed,\n",
    "                    'raw_count': len(detections)\n",
    "                }\n",
    "            \n",
    "            except Exception as e:\n",
    "                self.stats['errors'] += 1\n",
    "                if attempt == self.retry_attempts - 1:\n",
    "                    return {\n",
    "                        'success': False,\n",
    "                        'error': str(e),\n",
    "                        'attempts': attempt + 1\n",
    "                    }\n",
    "                time.sleep(1 * (attempt + 1))\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get detector statistics.\"\"\"\n",
    "        avg_time = np.mean(self.stats['detection_times']) if self.stats['detection_times'] else 0\n",
    "        \n",
    "        return {\n",
    "            **self.stats,\n",
    "            'avg_detection_time': avg_time,\n",
    "            'avg_detections_per_image': self.stats['total_detections'] / max(1, self.stats['total_predictions']),\n",
    "            'suppression_rate': self.stats['suppressed_detections'] / max(1, self.stats['total_detections']),\n",
    "            'error_rate': self.stats['errors'] / max(1, self.stats['total_predictions'] + self.stats['errors'])\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "print(\"Production Object Detector Example\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "detector = ProductionObjectDetector(\n",
    "    prediction_endpoint,\n",
    "    prediction_key,\n",
    "    project.id,\n",
    "    publish_name,\n",
    "    confidence_threshold=0.5,\n",
    "    nms_threshold=0.5,\n",
    "    enable_nms=True\n",
    ")\n",
    "\n",
    "if os.path.exists(test_image):\n",
    "    with open(test_image, 'rb') as f:\n",
    "        result = detector.detect(f.read())\n",
    "    \n",
    "    if result['success']:\n",
    "        print(f\"✓ Detection successful\")\n",
    "        print(f\"  Objects found: {result['num_objects']}\")\n",
    "        print(f\"  Detection time: {result['detection_time']*1000:.1f}ms\")\n",
    "        print(f\"  Raw detections: {result['raw_count']}\")\n",
    "        print(f\"\\nDetected objects:\")\n",
    "        for det in result['detections']:\n",
    "            print(f\"  - {det['tag']:10} ({det['confidence']:.2%})\")\n",
    "    \n",
    "    stats = detector.get_stats()\n",
    "    print(f\"\\nDetector Statistics:\")\n",
    "    print(f\"  Total predictions: {stats['total_predictions']}\")\n",
    "    print(f\"  Avg detection time: {stats['avg_detection_time']*1000:.1f}ms\")\n",
    "    print(f\"  Avg objects per image: {stats['avg_detections_per_image']:.1f}\")\n",
    "    print(f\"  Suppression rate: {stats['suppression_rate']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary\n",
    "\n",
    "### Advanced Concepts Covered:\n",
    "✓ IoU (Intersection over Union) calculation and interpretation  \n",
    "✓ Non-Maximum Suppression (NMS) for duplicate removal  \n",
    "✓ Performance optimization and benchmarking  \n",
    "✓ Multi-object scene analysis  \n",
    "✓ Real-time detection considerations  \n",
    "✓ Production-ready detector implementation  \n",
    "✓ Advanced monitoring and statistics  \n",
    "\n",
    "### Key Takeaways:\n",
    "1. **IoU** measures detection quality by quantifying bounding box overlap\n",
    "2. **NMS** eliminates redundant detections, improving results\n",
    "3. **Performance tuning** requires balancing speed vs accuracy\n",
    "4. **Real-time detection** needs optimization for target frame rates\n",
    "5. **Production deployment** requires robust error handling and monitoring\n",
    "\n",
    "### Best Practices:\n",
    "- Use NMS to clean up multiple detections of same object\n",
    "- Set IoU threshold based on your accuracy requirements\n",
    "- Monitor detection times and confidence distributions\n",
    "- Implement retry logic and error handling\n",
    "- Track suppression rates to tune NMS threshold\n",
    "- Consider edge deployment for real-time applications\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with different IoU and NMS thresholds\n",
    "- Implement tracking for video object detection\n",
    "- Export models for edge deployment\n",
    "- Build custom post-processing pipelines\n",
    "- Integrate with real-time video streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete project\n",
    "# training_client.delete_project(project.id)\n",
    "# print(\"Project deleted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
