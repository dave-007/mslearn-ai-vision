{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01: Analyze Images with Azure AI Vision\n",
    "\n",
    "## Overview\n",
    "Azure AI Vision is an artificial intelligence capability that enables software systems to interpret visual input by analyzing images. In this lab, you'll use the Azure AI Vision service to:\n",
    "- Generate captions and tags for images\n",
    "- Detect common objects in images\n",
    "- Detect people in images\n",
    "- Remove background or create foreground matting\n",
    "\n",
    "## Prerequisites\n",
    "- An Azure subscription with an Azure AI Vision resource\n",
    "- The endpoint and key for your Azure AI Vision resource\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this lab, you will be able to:\n",
    "- Authenticate with Azure AI Vision service\n",
    "- Analyze images to extract visual features\n",
    "- Detect and annotate objects and people in images\n",
    "- Visualize detection results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Packages\n",
    "\n",
    "First, let's install the necessary Python packages for working with Azure AI Vision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# Note: Uncomment the following line if running in a fresh environment\n",
    "# !pip install python-dotenv azure-ai-vision-imageanalysis==1.0.0 matplotlib pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Required Libraries\n",
    "\n",
    "Import all the necessary Python libraries for image analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import sys\n",
    "from matplotlib import pyplot as plt\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Enable inline plotting for Jupyter notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configure Azure AI Vision Credentials\n",
    "\n",
    "Load your Azure AI Vision endpoint and key from environment variables. You can either:\n",
    "1. Create a `.env` file in the `python/image-analysis` directory with your credentials\n",
    "2. Set the values directly in the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration from .env file\n",
    "load_dotenv('python/image-analysis/.env')\n",
    "\n",
    "# Get Configuration Settings\n",
    "ai_endpoint = os.getenv('AI_SERVICE_ENDPOINT')\n",
    "ai_key = os.getenv('AI_SERVICE_KEY')\n",
    "\n",
    "# Alternatively, set values directly (NOT recommended for production)\n",
    "# ai_endpoint = 'your_azure_ai_services_endpoint'\n",
    "# ai_key = 'your_azure_ai_services_key'\n",
    "\n",
    "# Validate credentials are loaded\n",
    "if not ai_endpoint or not ai_key or 'your_' in ai_endpoint or 'your_' in ai_key:\n",
    "    print(\"⚠ Warning: Please configure your Azure AI Vision credentials\")\n",
    "    print(\"  Update the .env file or set the values directly in this cell\")\n",
    "else:\n",
    "    print(f\"✓ Endpoint configured: {ai_endpoint[:30]}...\")\n",
    "    print(\"✓ API key loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Authenticate Azure AI Vision Client\n",
    "\n",
    "Create an authenticated client to interact with the Azure AI Vision service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate Azure AI Vision client\n",
    "cv_client = ImageAnalysisClient(\n",
    "    endpoint=ai_endpoint,\n",
    "    credential=AzureKeyCredential(ai_key)\n",
    ")\n",
    "\n",
    "print(\"✓ Azure AI Vision client authenticated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Analyze an Image\n",
    "\n",
    "Let's analyze an image to extract captions, tags, objects, and people. We'll use a street scene image as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the image to analyze\n",
    "image_file = 'python/image-analysis/images/street.jpg'\n",
    "\n",
    "# Display the image\n",
    "print(f\"Analyzing image: {image_file}\")\n",
    "img = Image.open(image_file)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Original Image')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Image size: {img.size[0]}x{img.size[1]} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Get Image Captions\n",
    "\n",
    "The Azure AI Vision service can generate descriptive captions for images using advanced AI models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image analysis with caption feature\n",
    "with open(image_file, \"rb\") as f:\n",
    "    image_data = f.read()\n",
    "\n",
    "result = cv_client.analyze(\n",
    "    image_data=image_data,\n",
    "    visual_features=[VisualFeatures.CAPTION]\n",
    ")\n",
    "\n",
    "# Display the caption\n",
    "if result.caption is not None:\n",
    "    print(\"\\n=== Image Caption ===\")\n",
    "    print(f\"Caption: '{result.caption.text}'\")\n",
    "    print(f\"Confidence: {result.caption.confidence:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Get Image Tags\n",
    "\n",
    "Tags provide descriptive keywords about the content of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image tags\n",
    "result = cv_client.analyze(\n",
    "    image_data=image_data,\n",
    "    visual_features=[VisualFeatures.TAGS]\n",
    ")\n",
    "\n",
    "# Display tags\n",
    "if result.tags is not None:\n",
    "    print(\"\\n=== Image Tags ===\")\n",
    "    print(f\"Found {len(result.tags.list)} tags:\")\n",
    "    for tag in result.tags.list:\n",
    "        print(f\"  • {tag.name} (confidence: {tag.confidence:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Detect Objects\n",
    "\n",
    "The service can identify common objects in images and provide their locations using bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get objects in the image\n",
    "result = cv_client.analyze(\n",
    "    image_data=image_data,\n",
    "    visual_features=[VisualFeatures.OBJECTS]\n",
    ")\n",
    "\n",
    "# Display detected objects\n",
    "if result.objects is not None:\n",
    "    print(\"\\n=== Detected Objects ===\")\n",
    "    print(f\"Found {len(result.objects.list)} objects:\")\n",
    "    for obj in result.objects.list:\n",
    "        print(f\"  • {obj.tags[0].name} (confidence: {obj.tags[0].confidence:.2%})\")\n",
    "        r = obj.bounding_box\n",
    "        print(f\"    Location: ({r.x}, {r.y}), Size: {r.width}x{r.height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Visualize Object Detection\n",
    "\n",
    "Let's draw bounding boxes around the detected objects to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_objects(image_filename, detected_objects):\n",
    "    \"\"\"\n",
    "    Draw bounding boxes around detected objects in an image.\n",
    "    \n",
    "    Args:\n",
    "        image_filename: Path to the image file\n",
    "        detected_objects: List of detected objects from Azure AI Vision\n",
    "    \"\"\"\n",
    "    print(\"\\nAnnotating objects...\")\n",
    "    \n",
    "    # Prepare image for drawing\n",
    "    image = Image.open(image_filename)\n",
    "    fig = plt.figure(figsize=(image.width/100, image.height/100))\n",
    "    plt.axis('off')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    color = 'cyan'\n",
    "    \n",
    "    for detected_object in detected_objects:\n",
    "        # Draw object bounding box\n",
    "        r = detected_object.bounding_box\n",
    "        bounding_box = ((r.x, r.y), (r.x + r.width, r.y + r.height)) \n",
    "        draw.rectangle(bounding_box, outline=color, width=3)\n",
    "        plt.annotate(detected_object.tags[0].name, (r.x, r.y), backgroundcolor=color)\n",
    "    \n",
    "    # Display annotated image\n",
    "    plt.imshow(image)\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.title('Detected Objects')\n",
    "    plt.show()\n",
    "    print(\"✓ Object annotation complete\")\n",
    "\n",
    "# Annotate the image with detected objects\n",
    "if result.objects is not None and len(result.objects.list) > 0:\n",
    "    annotate_objects(image_file, result.objects.list)\n",
    "else:\n",
    "    print(\"No objects detected to annotate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Detect People\n",
    "\n",
    "The Azure AI Vision service can also detect people in images and provide bounding boxes around them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get people in the image\n",
    "result = cv_client.analyze(\n",
    "    image_data=image_data,\n",
    "    visual_features=[VisualFeatures.PEOPLE]\n",
    ")\n",
    "\n",
    "# Display detected people\n",
    "if result.people is not None:\n",
    "    print(\"\\n=== Detected People ===\")\n",
    "    print(f\"Found {len(result.people.list)} people:\")\n",
    "    for person in result.people.list:\n",
    "        if person.confidence > 0.5:\n",
    "            r = person.bounding_box\n",
    "            print(f\"  • Person (confidence: {person.confidence:.2%})\")\n",
    "            print(f\"    Location: ({r.x}, {r.y}), Size: {r.width}x{r.height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6 Visualize People Detection\n",
    "\n",
    "Let's draw bounding boxes around the detected people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_people(image_filename, detected_people):\n",
    "    \"\"\"\n",
    "    Draw bounding boxes around detected people in an image.\n",
    "    \n",
    "    Args:\n",
    "        image_filename: Path to the image file\n",
    "        detected_people: List of detected people from Azure AI Vision\n",
    "    \"\"\"\n",
    "    print(\"\\nAnnotating people...\")\n",
    "    \n",
    "    # Prepare image for drawing\n",
    "    image = Image.open(image_filename)\n",
    "    fig = plt.figure(figsize=(image.width/100, image.height/100))\n",
    "    plt.axis('off')\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    color = 'cyan'\n",
    "    \n",
    "    for detected_person in detected_people:\n",
    "        if detected_person.confidence > 0.5:\n",
    "            # Draw bounding box\n",
    "            r = detected_person.bounding_box\n",
    "            bounding_box = ((r.x, r.y), (r.x + r.width, r.y + r.height))\n",
    "            draw.rectangle(bounding_box, outline=color, width=3)\n",
    "    \n",
    "    # Display annotated image\n",
    "    plt.imshow(image)\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.title('Detected People')\n",
    "    plt.show()\n",
    "    print(\"✓ People annotation complete\")\n",
    "\n",
    "# Annotate the image with detected people\n",
    "if result.people is not None and len(result.people.list) > 0:\n",
    "    annotate_people(image_file, result.people.list)\n",
    "else:\n",
    "    print(\"No people detected to annotate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Try Different Images\n",
    "\n",
    "Now let's analyze other images in the dataset. You can modify the `image_file` variable to analyze different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available images\n",
    "import glob\n",
    "\n",
    "image_dir = 'python/image-analysis/images'\n",
    "available_images = glob.glob(f\"{image_dir}/*.jpg\")\n",
    "\n",
    "print(\"Available images for analysis:\")\n",
    "for idx, img_path in enumerate(available_images, 1):\n",
    "    print(f\"{idx}. {os.path.basename(img_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze a different image (e.g., person.jpg or building.jpg)\n",
    "# Uncomment and run to analyze another image:\n",
    "\n",
    "# image_file = 'python/image-analysis/images/person.jpg'\n",
    "# # or\n",
    "# image_file = 'python/image-analysis/images/building.jpg'\n",
    "\n",
    "# # Display the image\n",
    "# img = Image.open(image_file)\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# plt.imshow(img)\n",
    "# plt.axis('off')\n",
    "# plt.title(f'Analyzing: {os.path.basename(image_file)}')\n",
    "# plt.show()\n",
    "\n",
    "# # Get comprehensive analysis\n",
    "# with open(image_file, \"rb\") as f:\n",
    "#     image_data = f.read()\n",
    "\n",
    "# result = cv_client.analyze(\n",
    "#     image_data=image_data,\n",
    "#     visual_features=[VisualFeatures.CAPTION, VisualFeatures.TAGS, \n",
    "#                      VisualFeatures.OBJECTS, VisualFeatures.PEOPLE]\n",
    "# )\n",
    "\n",
    "# # Display all results\n",
    "# if result.caption:\n",
    "#     print(f\"\\nCaption: {result.caption.text} ({result.caption.confidence:.2%})\")\n",
    "# if result.tags:\n",
    "#     print(f\"\\nTop Tags: {', '.join([t.name for t in result.tags.list[:5]])}\")\n",
    "# if result.objects:\n",
    "#     print(f\"\\nObjects: {len(result.objects.list)} detected\")\n",
    "#     annotate_objects(image_file, result.objects.list)\n",
    "# if result.people:\n",
    "#     print(f\"\\nPeople: {len(result.people.list)} detected\")\n",
    "#     annotate_people(image_file, result.people.list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lab, you learned how to:\n",
    "- ✓ Set up and authenticate with Azure AI Vision service\n",
    "- ✓ Extract captions and tags from images using AI\n",
    "- ✓ Detect objects and people in images\n",
    "- ✓ Visualize detection results with bounding boxes\n",
    "- ✓ Analyze multiple images programmatically\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Try the **Advanced Image Analysis** notebook to explore more features like:\n",
    "  - Smart cropping for thumbnails\n",
    "  - Background removal\n",
    "  - Dense captioning\n",
    "  - Reading text in images (OCR)\n",
    "- Explore the [Azure AI Vision documentation](https://learn.microsoft.com/azure/ai-services/computer-vision/)\n",
    "- Learn about [best practices for image analysis](https://learn.microsoft.com/azure/ai-services/computer-vision/overview-image-analysis)\n",
    "\n",
    "## Clean Up\n",
    "\n",
    "Remember to manage your Azure resources to avoid unexpected charges. You can keep the resources for the next labs or delete them if no longer needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
