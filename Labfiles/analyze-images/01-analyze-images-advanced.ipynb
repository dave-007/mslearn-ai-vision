{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Image Analysis with Azure AI Vision\n",
    "\n",
    "## Overview\n",
    "This notebook explores advanced features of Azure AI Vision that go beyond the basic image analysis covered in Lab 01. You'll learn about:\n",
    "- Smart cropping and thumbnail generation\n",
    "- Background removal and foreground matting\n",
    "- Dense captioning (region-specific descriptions)\n",
    "- Adult/racy/gory content detection\n",
    "- Brand detection\n",
    "- Celebrity and landmark recognition\n",
    "\n",
    "## Prerequisites\n",
    "- Completed Lab 01: Analyze Images\n",
    "- Azure AI Vision resource with endpoint and key configured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# !pip install python-dotenv azure-ai-vision-imageanalysis==1.0.0 matplotlib pillow requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "from matplotlib import pyplot as plt\n",
    "from azure.ai.vision.imageanalysis import ImageAnalysisClient\n",
    "from azure.ai.vision.imageanalysis.models import VisualFeatures\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "load_dotenv('python/image-analysis/.env')\n",
    "\n",
    "ai_endpoint = os.getenv('AI_SERVICE_ENDPOINT')\n",
    "ai_key = os.getenv('AI_SERVICE_KEY')\n",
    "\n",
    "# Create authenticated client\n",
    "cv_client = ImageAnalysisClient(\n",
    "    endpoint=ai_endpoint,\n",
    "    credential=AzureKeyCredential(ai_key)\n",
    ")\n",
    "\n",
    "print(\"‚úì Azure AI Vision client configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Smart Cropping for Thumbnails\n",
    "\n",
    "Smart cropping uses AI to identify the most important region of an image and crops it intelligently to create thumbnails that preserve the main subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image for smart cropping\n",
    "image_file = 'python/image-analysis/images/person.jpg'\n",
    "\n",
    "with open(image_file, \"rb\") as f:\n",
    "    image_data = f.read()\n",
    "\n",
    "# Display original image\n",
    "img = Image.open(image_file)\n",
    "print(f\"Original image size: {img.size}\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Original Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get smart crop suggestions\n",
    "result = cv_client.analyze(\n",
    "    image_data=image_data,\n",
    "    visual_features=[VisualFeatures.SMART_CROPS]\n",
    ")\n",
    "\n",
    "if result.smart_crops is not None:\n",
    "    print(f\"\\nSmart Crop Suggestions: {len(result.smart_crops.list)}\")\n",
    "    \n",
    "    # Display the top smart crop suggestion\n",
    "    top_crop = result.smart_crops.list[0]\n",
    "    print(f\"\\nTop suggestion - Aspect Ratio: {top_crop.aspect_ratio:.2f}\")\n",
    "    print(f\"Bounding Box: x={top_crop.bounding_box.x}, y={top_crop.bounding_box.y}, \"\n",
    "          f\"width={top_crop.bounding_box.width}, height={top_crop.bounding_box.height}\")\n",
    "    \n",
    "    # Crop and display the smart crop\n",
    "    img = Image.open(image_file)\n",
    "    r = top_crop.bounding_box\n",
    "    cropped = img.crop((r.x, r.y, r.x + r.width, r.y + r.height))\n",
    "    \n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cropped)\n",
    "    plt.axis('off')\n",
    "    plt.title('Smart Cropped Thumbnail')\n",
    "    plt.show()\n",
    "    print(f\"Cropped image size: {cropped.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dense Captions (Region-Specific Descriptions)\n",
    "\n",
    "Dense captioning provides multiple captions for different regions of an image, allowing you to understand specific areas in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze image with dense captions\n",
    "image_file = 'python/image-analysis/images/street.jpg'\n",
    "\n",
    "with open(image_file, \"rb\") as f:\n",
    "    image_data = f.read()\n",
    "\n",
    "result = cv_client.analyze(\n",
    "    image_data=image_data,\n",
    "    visual_features=[VisualFeatures.DENSE_CAPTIONS]\n",
    ")\n",
    "\n",
    "# Display image\n",
    "img = Image.open(image_file)\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Image with Dense Captions')\n",
    "plt.show()\n",
    "\n",
    "# Display dense captions\n",
    "if result.dense_captions is not None:\n",
    "    print(f\"\\n=== Dense Captions ({len(result.dense_captions.list)} regions) ===\")\n",
    "    for idx, caption in enumerate(result.dense_captions.list, 1):\n",
    "        print(f\"\\n{idx}. \\\"{caption.text}\\\" (confidence: {caption.confidence:.2%})\")\n",
    "        if caption.bounding_box:\n",
    "            r = caption.bounding_box\n",
    "            print(f\"   Region: ({r.x}, {r.y}) - {r.width}x{r.height}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Background Removal\n",
    "\n",
    "Azure AI Vision can remove backgrounds from images or create foreground matting, useful for e-commerce, profile pictures, and image editing applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Background removal requires a REST API call\n",
    "# It's not available through the standard SDK analyze method\n",
    "\n",
    "def remove_background(image_path, mode='backgroundRemoval'):\n",
    "    \"\"\"\n",
    "    Remove background from an image using Azure AI Vision.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the input image\n",
    "        mode: 'backgroundRemoval' or 'foregroundMatting'\n",
    "    \n",
    "    Returns:\n",
    "        PIL Image with background removed\n",
    "    \"\"\"\n",
    "    # Construct the API endpoint\n",
    "    url = f\"{ai_endpoint}/computervision/imageanalysis:segment?api-version=2023-02-01-preview&mode={mode}\"\n",
    "    \n",
    "    # Read image data\n",
    "    with open(image_path, 'rb') as f:\n",
    "        image_data = f.read()\n",
    "    \n",
    "    # Make API request\n",
    "    headers = {\n",
    "        'Ocp-Apim-Subscription-Key': ai_key,\n",
    "        'Content-Type': 'application/octet-stream'\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, headers=headers, data=image_data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Load the result image\n",
    "        result_image = Image.open(BytesIO(response.content))\n",
    "        return result_image\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        return None\n",
    "\n",
    "# Remove background from an image\n",
    "image_file = 'python/image-analysis/images/person.jpg'\n",
    "\n",
    "print(\"Processing background removal...\")\n",
    "print(\"Note: This feature may require preview API access\")\n",
    "\n",
    "try:\n",
    "    result_image = remove_background(image_file)\n",
    "    \n",
    "    if result_image:\n",
    "        # Display original and result side by side\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        \n",
    "        original = Image.open(image_file)\n",
    "        axes[0].imshow(original)\n",
    "        axes[0].axis('off')\n",
    "        axes[0].set_title('Original Image')\n",
    "        \n",
    "        axes[1].imshow(result_image)\n",
    "        axes[1].axis('off')\n",
    "        axes[1].set_title('Background Removed')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(\"‚úì Background removal complete\")\n",
    "except Exception as e:\n",
    "    print(f\"Background removal not available: {e}\")\n",
    "    print(\"This feature may require preview API access or specific service configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Content Moderation\n",
    "\n",
    "Detect adult, racy, or gory content in images for content moderation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze image for adult content\n",
    "image_file = 'python/image-analysis/images/building.jpg'\n",
    "\n",
    "with open(image_file, \"rb\") as f:\n",
    "    image_data = f.read()\n",
    "\n",
    "# Note: Adult content detection is typically done via REST API\n",
    "# This is a demonstration of how to structure the call\n",
    "\n",
    "print(\"\\n=== Content Moderation Analysis ===\")\n",
    "print(\"Analyzing image for inappropriate content...\")\n",
    "\n",
    "# Using the REST API for adult content detection\n",
    "url = f\"{ai_endpoint}/vision/v3.2/analyze?visualFeatures=Adult\"\n",
    "headers = {\n",
    "    'Ocp-Apim-Subscription-Key': ai_key,\n",
    "    'Content-Type': 'application/octet-stream'\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.post(url, headers=headers, data=image_data)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        adult = result.get('adult', {})\n",
    "        \n",
    "        print(f\"\\nAdult Content: {adult.get('isAdultContent', False)}\")\n",
    "        print(f\"Adult Score: {adult.get('adultScore', 0):.3f}\")\n",
    "        print(f\"\\nRacy Content: {adult.get('isRacyContent', False)}\")\n",
    "        print(f\"Racy Score: {adult.get('racyScore', 0):.3f}\")\n",
    "        print(f\"\\nGory Content: {adult.get('isGoryContent', False)}\")\n",
    "        print(f\"Gory Score: {adult.get('goryScore', 0):.3f}\")\n",
    "        \n",
    "        # Display the analyzed image\n",
    "        img = Image.open(image_file)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title('Content Moderation Analysis')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"Content moderation analysis not available: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Image Analysis with Multiple Features\n",
    "\n",
    "Combine multiple visual features in a single API call for comprehensive image analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_analysis(image_path):\n",
    "    \"\"\"\n",
    "    Perform comprehensive image analysis with multiple features.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to the image file\n",
    "    \"\"\"\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        image_data = f.read()\n",
    "    \n",
    "    # Request all available features\n",
    "    result = cv_client.analyze(\n",
    "        image_data=image_data,\n",
    "        visual_features=[\n",
    "            VisualFeatures.CAPTION,\n",
    "            VisualFeatures.DENSE_CAPTIONS,\n",
    "            VisualFeatures.TAGS,\n",
    "            VisualFeatures.OBJECTS,\n",
    "            VisualFeatures.PEOPLE,\n",
    "            VisualFeatures.SMART_CROPS,\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Display the image\n",
    "    img = Image.open(image_path)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Comprehensive Image Analysis')\n",
    "    plt.show()\n",
    "    \n",
    "    # Display all results\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"COMPREHENSIVE IMAGE ANALYSIS RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if result.caption:\n",
    "        print(f\"\\nüìù Main Caption: {result.caption.text}\")\n",
    "        print(f\"   Confidence: {result.caption.confidence:.2%}\")\n",
    "    \n",
    "    if result.dense_captions:\n",
    "        print(f\"\\nüìç Dense Captions: {len(result.dense_captions.list)} regions\")\n",
    "        for idx, caption in enumerate(result.dense_captions.list[:3], 1):\n",
    "            print(f\"   {idx}. {caption.text} ({caption.confidence:.2%})\")\n",
    "    \n",
    "    if result.tags:\n",
    "        print(f\"\\nüè∑Ô∏è  Tags ({len(result.tags.list)}):\")\n",
    "        top_tags = result.tags.list[:10]\n",
    "        print(\"   \" + \", \".join([f\"{t.name} ({t.confidence:.0%})\" for t in top_tags]))\n",
    "    \n",
    "    if result.objects:\n",
    "        print(f\"\\nüéØ Objects: {len(result.objects.list)} detected\")\n",
    "        for obj in result.objects.list[:5]:\n",
    "            print(f\"   ‚Ä¢ {obj.tags[0].name} ({obj.tags[0].confidence:.2%})\")\n",
    "    \n",
    "    if result.people:\n",
    "        print(f\"\\nüë• People: {len(result.people.list)} detected\")\n",
    "        for person in result.people.list:\n",
    "            if person.confidence > 0.5:\n",
    "                print(f\"   ‚Ä¢ Person ({person.confidence:.2%})\")\n",
    "    \n",
    "    if result.smart_crops:\n",
    "        print(f\"\\n‚úÇÔ∏è  Smart Crops: {len(result.smart_crops.list)} suggestions\")\n",
    "        for crop in result.smart_crops.list[:3]:\n",
    "            print(f\"   ‚Ä¢ Aspect ratio: {crop.aspect_ratio:.2f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Analyze an image comprehensively\n",
    "image_file = 'python/image-analysis/images/street.jpg'\n",
    "comprehensive_analysis(image_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Batch Image Analysis\n",
    "\n",
    "Process multiple images efficiently in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Get all images in the directory\n",
    "image_dir = 'python/image-analysis/images'\n",
    "image_files = glob.glob(f\"{image_dir}/*.jpg\")\n",
    "\n",
    "print(f\"Processing {len(image_files)} images...\\n\")\n",
    "\n",
    "# Analyze each image\n",
    "results_summary = []\n",
    "\n",
    "for image_path in image_files:\n",
    "    image_name = os.path.basename(image_path)\n",
    "    print(f\"Analyzing: {image_name}\")\n",
    "    \n",
    "    try:\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            image_data = f.read()\n",
    "        \n",
    "        result = cv_client.analyze(\n",
    "            image_data=image_data,\n",
    "            visual_features=[VisualFeatures.CAPTION, VisualFeatures.TAGS]\n",
    "        )\n",
    "        \n",
    "        caption = result.caption.text if result.caption else \"N/A\"\n",
    "        top_tags = [t.name for t in result.tags.list[:3]] if result.tags else []\n",
    "        \n",
    "        results_summary.append({\n",
    "            'file': image_name,\n",
    "            'caption': caption,\n",
    "            'top_tags': ', '.join(top_tags)\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")\n",
    "        results_summary.append({\n",
    "            'file': image_name,\n",
    "            'caption': 'Error',\n",
    "            'top_tags': str(e)\n",
    "        })\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BATCH ANALYSIS SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "for summary in results_summary:\n",
    "    print(f\"\\n{summary['file']}\")\n",
    "    print(f\"  Caption: {summary['caption']}\")\n",
    "    print(f\"  Tags: {summary['top_tags']}\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this advanced lab, you explored:\n",
    "- ‚úì Smart cropping for intelligent thumbnail generation\n",
    "- ‚úì Dense captioning for region-specific descriptions\n",
    "- ‚úì Background removal and foreground matting\n",
    "- ‚úì Content moderation for adult/racy/gory content\n",
    "- ‚úì Comprehensive multi-feature analysis\n",
    "- ‚úì Batch processing of multiple images\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [Azure AI Vision API Reference](https://learn.microsoft.com/azure/ai-services/computer-vision/)\n",
    "- [Image Analysis concepts](https://learn.microsoft.com/azure/ai-services/computer-vision/concept-image-analysis)\n",
    "- [Background removal documentation](https://learn.microsoft.com/azure/ai-services/computer-vision/concept-background-removal)\n",
    "- [Smart cropping guide](https://learn.microsoft.com/azure/ai-services/computer-vision/how-to/generate-thumbnails)\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Try applying these advanced features to your own images and use cases:\n",
    "- E-commerce: Smart cropping for product thumbnails\n",
    "- Content moderation: Filtering inappropriate images\n",
    "- Photo editing: Background removal for profile pictures\n",
    "- Accessibility: Dense captions for detailed image descriptions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
